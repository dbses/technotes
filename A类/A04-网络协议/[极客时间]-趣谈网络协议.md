# 02 | 网络分层的真实含义是什么？

**这四个问题你真的懂了吗？**

- TCP在进行三次握手的时候，IP层和MAC层对应都有什么操作呢？
- A知道自己的下一个中转站是B，那从A发出来的包，应该把B的IP地址放在哪里呢？B知道自己的下一个中转站是C，从B发出来的包，应该把C的IP地址放在哪里呢？如果放在IP协议中的目标地址，那包到了中转站，怎么知道最终的目的地址是D呢？
- 二层设备处理的通常是MAC层的东西，二层设备处理的包里，有没有HTTP层的内容呢？
- 你打开一个电商网站，都需要经历哪些过程？

**网络为什么要分层？**

复杂的程序都要分层，这是程序设计的要求。比如，复杂的电商还会分数据库层、缓存层、Compose层、Controller层和接入层，每一层专注做本层的事情。

**程序是如何工作的？**

<img src="https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091848.jpg" style="zoom: 80%;" />

**揭秘层与层之间的关系**

只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。所以，对TCP协议来说，三次握手也好，重试也好，只要想发出去包，就要有IP层和MAC层，不然是发不出去的。

# 03 | ifconfig：最熟悉又陌生的命令行

除了`ifconfig`命令外，可以通过`ip addr`查看本机`ip`地址。

```
root@test:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff
    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fec7:7975/64 scope link 
       valid_lft forever preferred_lft forever
```

本来32位的IP地址就不够，还被分成了5类。现在想想，当时分配地址的时候，真是太奢侈了。

<img src="https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091903.jpg" style="zoom: 80%;" />

在网络地址中，至少在当时设计的时候，对于A、B、 C类主要分两部分，前面一部分是网络号，后面一部分是主机号。

<img src="https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091915.jpg" style="zoom:80%;" />

# 10 | UDP协议：因性善而简单，难免碰到“城会玩”

**TCP和UDP有哪些区别？**

TCP是面向连接的，UDP是面向无连接的。所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。

TCP提供可靠交付。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。而UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。

TCP是面向字节流的。发送的时候发的是一个流，没头没尾。IP包可不是一个流，而是一个个的IP包。之所以变成了流，这也是TCP自己的状态维护做的事情。而UDP继承了IP的特性，基于数据报的，一个一个地发，一个一个地收。

TCP是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP就不会，应用让我发，我就发，管它洪水滔天。

**UDP包头是什么样的？**

无论应用程序是使用TCP传数据，还是UDP传数据，都要监听一个端口。

<img src="https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091930.jpg"  />

# 11 | TCP协议（上）：因性恶而复杂，先恶后善反轻松

**TCP包头格式**

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091936.jpg)

源端口号和目标端口号：保证数据流发给哪个应用。<br>包的序号：编好号确认哪个先来，哪个后到，是为了解决乱序的问题。<br>确认序号：发出去的包应该有确认，如果没有收到就应该重新发送，直到送达。<br>状态位：SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接，PSH是数据推送。<br>窗口大小：TCP要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力。

除了做流量控制以外，TCP还会做拥塞控制。

**TCP三次握手**

TCP的连接建立，需要经历“请求->应答->应答之应答”的三个回合，称为三次握手。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091944.jpg)

为什么两次握手不行？

A建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B会认为这也是一个正常的的请求的话，因此建立了连接。有问题。

三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是TCP包的序号的问题。

每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个32位的计数器，每4ms加一。为什么序号不能都从1开始呢？因为这样往往会出现冲突。

**TCP四次挥手**

好了，说完了连接，接下来说一说“拜拜”，好说好散。这常被称为四次挥手。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119091956.jpg)

断开的时候，我们可以看到，当A说“不玩了”，就进入FIN_WAIT_1的状态，B收到“A不玩”的消息后，发送知道了，就进入CLOSE_WAIT的状态。

A收到“B说知道了”，就进入FIN_WAIT_2的状态，如果这个时候B直接跑路，则A将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整`tcp_fin_timeout`这个参数，设置一个超时时间。

如果B没有跑路，发送了“B也不玩了”的请求到达A时，A发送“知道B也不玩了”的ACK后，从FIN_WAIT_2状态结束，按说A可以跑路了，但是最后的这个ACK万一B收不到呢？则B会重新发一个“B不玩了”，这个时候A已经跑路了的话，B就再也收不到ACK了，因而TCP协议要求A最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果B没收到ACK的话，“B说不玩了”会重发的，A会重新发一个ACK并且足够时间到达B。

A直接跑路还有一个问题是，A的端口就直接空出来了，但是B不知道，B原来发过的很多包很可能还在路上，如果A的端口被一个新的应用占用了，这个新的应用会收到上个连接中B发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来B发送的所有的包都死翘翘，再空出端口来。

等待的时间设为2MSL，**MSL**是**Maximum Segment Lifetime**，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文是基于IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。

还有一个异常情况就是，B超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，B当然还会重发FIN，这个时候A再收到这个包之后，A就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送RST，B就知道A早就跑了。

下面是一道情景面试：

<img src="https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092004.jpg" style="zoom: 67%;" />

**TCP状态机**

将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的TCP的状态机。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092028.jpg)

在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端A的状态变迁，加粗的虚线是服务端B的状态变迁。

# （补充）TIME_WAIT：隐藏在细节下的魔鬼

> 来源于盛延敏极客专栏《网络编程实战》第10讲

**TIME_WAIT 的作用**

首先，这样做是为了确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。

第二，为了让旧连接的重复分节在网络中自然消失。

**TIME_WAIT 的危害**

第一是内存资源占用，这个目前看来不是太严重，基本可以忽略。

第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000。

**如何优化 TIME_WAIT？**

- net.ipv4.tcp_max_tw_buckets

  这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置，并且只打印出警告信息。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。

- 调低 TCP_TIMEWAIT_LEN，重新编译系统

  这个方法是一个不错的方法，缺点是需要“一点”内核方面的知识，能够重新编译内核。我想这个不是大多数人能接受的方式。

- SO_LINGER 的设置

  英文单词“linger”的意思为停留，我们可以通过设置套接字选项，来设置调用 close 或者 shutdown 关闭连接时的行为。

- net.ipv4.tcp_tw_reuse：更安全的设置

  从协议角度理解如果是安全可控的，可以复用处于 TIME_WAIT 的套接字为新的连接所用。

# 12 | TCP协议（下）：西行必定多妖孽，恒心智慧消磨难

**如何做个靠谱的人？**

需要很多的机制去保证传输的可靠性，这里面需要恒心，也即各种重传的策略，还需要有智慧，也就是说，这里面包含着大量的算法。

**如何实现一个靠谱的协议？**

- 累计确认或者累计应答（cumulative acknowledgment）

  为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了

为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的ID一个个排列，根据处理的情况分成四个部分。

第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。<br>第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。<br>第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。<br>第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。

- 窗口控制

  在TCP里，接收端会给发送端报一个窗口的大小，叫**Advertised window**。这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。

于是，发送端需要保持下面的数据结构。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092038.jpg)

LastByteAcked：第一部分和第二部分的分界线；<br>LastByteSent：第二部分和第三部分的分界线；<br>LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线。

对于接收端来讲，它的缓存里记录的内容要简单一些。

第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。<br>第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。<br>第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。

对应的数据结构就像这样。 ﻿﻿

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092045.jpg)

MaxRcvBuffer：最大缓存的量；<br>LastByteRead之后是已经接收了，但是还没被应用层读取的；<br>NextByteExpected是第一部分和第二部分的分界线。

第二部分的窗口有多大呢？

NextByteExpected和LastByteRead的差其实是还没被应用层读取的部分占用掉的MaxRcvBuffer的量，我们定义为A。AdvertisedWindow其实是MaxRcvBuffer减去A。也就是：AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。

那第二部分和第三部分的分界线在哪里呢？NextByteExpected加AdvertisedWindow就是第二部分和第三部分的分界线，其实也就是LastByteRead加上MaxRcvBuffer。

**顺序问题与丢包问题**

我们结合一个例子来看。还是刚才的图，在发送端来看，1、2、3已经发送并确认；4、5、6、7、8、9都是发送了还没确认；10、11、12是还没发出的；13、14、15是接收方没有空间，不准备发的。

在接收端来看，1、2、3、4、5是已经完成ACK，但是没读取的；6、7是等待接收的；8、9是已经接收，但是没有ACK的。

发送端和接收端当前的状态如下：

1、2、3没有问题，双方达成了一致。<br>4、5接收方说ACK了，但是发送方还没收到，有可能丢了，有可能在路上。<br>6、7、8、9肯定都发了，但是8、9已经到了，但是6、7没到。

出现了乱序，缓存着但是没办法ACK。

根据这个例子，我们可以知道，顺序问题和丢包问题都有可能发生。

- 确认与重发机制

假设4的确认到了，不幸的是，5的ACK丢了，6、7的数据包丢了，这该怎么办呢？

一种方法就是**超时重试**，也即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过了一定的时间，就重新尝试。但是这个超时的时间如何评估呢？这个时间不宜过短，时间必须大于往返时间RTT，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。

估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为**自适应重传算法**（**Adaptive Retransmission Algorithm**）。

如果过一段时间，5、6、7都超时了，就会重新发送。接收方发现5原来接收过，于是丢弃5；6收到了，发送ACK，要求下一个是7，7不幸又丢了。当7再次超时的时候，有需要重传的时候，TCP的策略是**超时间隔加倍**。**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。**两次超时，就说明网络环境差，不宜频繁反复发送。**

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

例如，接收方发现6、8、9都已经接收了，就是7没来，那肯定是丢了，于是发送三个6的ACK，要求下一个是7。客户端收到3个，就会发现7的确又丢了，不等超时，马上重发。

还有一种方式称为**Selective Acknowledgment** （**SACK**）。这种方式需要在TCP头里加一个SACK的东西，可以将缓存的地图发送给发送方。例如可以发送ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是7丢了。

**流量控制问题**

我们再来看流量控制机制，在对于包的确认中，同时会携带一个窗口的大小。我们先假设窗口不变的情况，窗口始终为9。4的确认来的时候，会右移一个，这个时候第13个包也可以发送了。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092054.jpg)

这个时候，假设发送端发送过猛，会将第三部分的10、11、12、13全部发送完毕，之后就停止发送了，未发送可发送部分为0。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092100.jpg)

当对于包5的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第14个包才可以发送。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092107.jpg)

如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为0，则发送方将暂时停止发送。

我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包6确认后，窗口大小就不能再是9了，就要缩小一个变为8。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092112.jpg)

这个新的窗口8通过6的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从9改成了8。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092119.jpg)

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为0。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092125.jpg)

当这个窗口通过包14的确认到达发送端的时候，发送端的窗口也调整为0，停止发送。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092131.jpg)

如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

这就是我们常说的流量控制。

**拥塞控制问题**

最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，前面的滑动窗口`rwnd`是怕发送方把接收方缓存塞满，而拥塞窗口`cwnd`，是怕把网络塞满。

如果我们设置发送窗口，使得发送但未确认的包为为通道的容量，就能够撑满整个管道。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092137.jpg)

如图所示，已经造成了网络拥塞。

假设往返时间为8s，去4s，回4s，每秒发送一个包，每个包1024byte。已经过去了8s，则8个包都发出去了，其中前4个包已经到达接收端，但是ACK还没有返回，不能算发送成功。5-8后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为8个包，正好等于带宽，也即每秒发送1个包，乘以来回时间8s。

如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？

我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费1s，所以到达另一端需要耗费4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。

这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。

于是TCP的拥塞控制主要来避免两种现象，**包丢失**和**超时重传**。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢？

一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认cwnd加一，两个确认cwnd加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认cwnd加一，四个确认cwnd加四，于是一次能够发送八个。可以看出这是**指数性的增长**。

涨到什么时候是个头呢？有一个值ssthresh为65535个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。

每收到一个确认后，cwnd增加1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加1/8，八个确认一共cwnd增加1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。

前面我们讲过**快速重传算法**。当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd减半为cwnd/2，然后sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092146.jpg)

就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，TCP的拥塞控制主要来避免的两个现象都是有问题的。

**第一个问题**是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

**第二个问题**是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了**TCP BBR拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201119092152.jpg)

