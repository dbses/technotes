> 来源：极客时间《架构实战案例解析》

# 11 | 技术架构：作为开发，你真的了解系统吗？

这一讲，我想先跟你聊聊技术架构要解决什么问题。

**系统的物理模型**

我们先看下一个系统的具体组成。

![image-20220407222249265](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204072222960.png)

从用户请求的处理过程来看，系统主要包括五大部分。

- 接入系统

它负责接收用户的请求，然后把用户的请求分发到某个 Web 服务器进行处理。

- 应用系统

我们是基于某个开发框架来开发应用的，比如 Java 应用一般是基于 Spring MVC 框架；我们的应用代码，会调用开发语言提供的库和各种第三方的库，比如 JDK 和 Log4j。

- 基础平台

首先是各个语言的运行时，比如说 JVM；然后是容器或虚拟机；下面还有操作系统；最底下就是硬件和网络。

- 核心组件

在大多数情况下，应用系统还要借助大量外部的中间件来实现功能和落地数据，比如数据库、缓存、消息队列，以及 RPC 通讯框架等等。

- 支撑系统

包括日志系统、配置系统，还有大量的运维系统，它们提供监控、安全、资源调度等功能，它们和核心组件的区别是，这些系统一般不参与实际的用户请求处理，但它们在背后默默保障系统的正常运行。

**技术架构的挑战**

- 硬件的问题

从技术架构的角度，提升硬件的处理能力一般有两种方式：Scale Up 和 Scale Out。

垂直扩展有物理上的瓶颈或成本的问题。受硬件的物理限制，机器的性能是有天花板的。水平扩展如何有效地管理大量的机器，硬件不是 100% 的可靠，它本身也会出问题。

我们在做技术架构设计时，就要充分考虑各种硬件故障的可能性，做好应对方案。比如说针对自然灾害，系统做异地多机房部署。

- 软件的问题

这里的软件，主要说的是各种中间件和系统级软件。软件在填硬件的各种坑的同时，也给系统挖了新的坑。

举个例子，Redis 集群的多节点，它解决了单节点处理能力问题，但同时也带来了新的问题，比如节点内部的网络有问题（即网络分区现象），集群的可用性就有问题；Redis 数据的多副本，它解决了单台服务器故障带来的可用性问题，但同时也带来了数据的一致性问题。

**技术架构的目标**

什么是系统非功能性需求呢？比如一个订单页面打开需要多少时间，页面是不是每次都能打开，这些就和具体的业务逻辑没有关系，属于系统非功能性需求的范畴。

对于一个系统来说，技术架构都要解决哪些非功能性需求呢？

- 系统的高可用

导致系统可用性出问题，一般是两种情况：一种是软硬件本身有故障，比如机器断电，网络不通；

还有一种是高并发引起的系统处理能力的不足，软硬件系统经常在处理能力不足时，直接瘫痪掉，比如 CPU 100% 的时候，整个系统完全不工作。

- 系统的高性能

保证合理的性能分两种情况：一种是常规的流量进来，但系统内部处理比较复杂，我们就需要运用技术手段进行优化。比如针对海量商品的检索，我们就需要构建复杂的搜索系统来支持。

第二种是高并发的流量进来，系统仍旧需要在合理的时间内提供响应，这就更强调我们做架构设计时，要保证系统的处理能力能够整体上做水平扩展，而不仅仅是对某个节点做绝对的性能优化，因为流量的提升是很难准确预计的。

- 系统的可伸缩和低成本

我们的架构设计要保证系统在业务高峰时，要能快速地增加资源来提升系统处理能力；反之，当业务低谷时，可以快速地减少系统资源，保证系统的低成本。

# 12 | 高可用架构：如何让你的系统不掉链子？

**系统有哪些故障点？**

这里，我用红色部分，标识出了整个处理过程中可能出现的故障点，如下图所示：

![image-20220408224204644](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204082242683.png)

这些故障点可以归纳为三类：

1. 资源不可用。包括网络和服务器出故障，网络出故障表明节点连接不上，服务器出故障表明该节点本身不能正常工作。
2. 资源不够用。常规的流量进来，节点能正常工作，但在高并发的情况下，节点无法正常工作，对外表现为响应超时。
3. 节点的功能有问题。比如接口的内部业务逻辑有问
   题。

**高可用策略和架构原则**

高可用的总体解决思路如下。

![image-20220408222440853](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204082224989.png)

- 避免发生

要想让系统能够稳定可用，我们首先要考虑如何避免问题的发生。比如说，我们可以通过事先增加机器来解决硬件资源不足的问题。

- 转移故障

如果问题真的发生了，我们就要考虑怎么转移故障（Failover）。比如说，我们可以通过冗余部署，当一个节点发生故障时，用其它正常的节点来代替问题节点。

- 降低影响

如果故障无法以正面的方式解决，我们就要努力降低故障带来的影响。比如说流量太大，我们可以通过限流，来保证部分用户可以正常使用，或者通过业务降级的手段，关闭一些次要功能，保证核心功能仍旧可用。

- 快速恢复

我们要尽快找到问题的原因，然后修复故障节点，使系统恢复到正常状态。

我们在做架构设计时，就可以从正面保障和减少损失两个角度来考虑具体的应对手段。

![image-20220408222531081](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204082225124.png)

第一个设计原则是冗余无单点。在接入层中，我们可以实现负载均衡的双节点部署，这样在一个节点出现问题时，另一个节点可以快速接管，继续提供服务。

第二个设计原则是水平扩展。我们需要通过增加机器数量，水平扩展这些节点的处理能力。

对于无状态的计算节点，比如应用层和服务层来说，水平扩展相对容易，我们直接增加机器就可以了；而对于有状态的节点，比如数据库，我们可以通过水平分库做水平扩展，不过这个需要应用一起配合，做比较大的改造。

第三个原则是柔性事务。在实践中，我们更多地使用 BASE 理论来指导系统设计。

我们平时对单个数据库事务的 ACID，因为这里不存在 P，所以 C 和 A 都能得到很好地保证，这是一种刚性事务。但在复杂的分布式场景下，基于 BASE 理论，我们通常只能实现部分的 C（软状态和最终一致）和部分的 A（基本可用），这是一种柔性事务。

柔性事务具体的实现方式有很多，比如说，通过异步消息在节点间同步数据。

第四个原则是系统可降级。当系统问题无法在短时间内解决时，我们就要考虑尽快止损，为故障支付尽可能小的代价。具体的解决手段主要有以下这几种。

- 限流：让部分用户流量进入系统处理，其它流量直接抛弃。

- 降级：系统抛弃部分不重要的功能，比如不发送短信通知，以此确保核心功能不受影响。

- 熔断：我们不去调用出问题的服务，让系统绕开故障点，切断通路，避免系统资源大量被占用。

  > 比如，用户下单时，如果积分服务出现问题，我们就先不送积分，后续再补偿。

- 功能禁用：针对具体的功能，我们设置好功能开关。比如商品搜索，在系统繁忙时，我们可以选择不进行复杂的深度搜索。

最后一个设计原则，是系统可监控。

**高可用手段**

- 客户端 -> 接入层

客户端到服务端通常是远程访问，所以我们首先要解决网络的可用性问题。

针对网络的高可用，我们可以拉多条线路，比如在企业私有的 IDC 机房和公有云之间，同时拉移动和电信的线路，让其中一条线路作为备份，当主线路有问题时就切换到备份线路上。

在接入层，也有很多成熟的 HA 方案，比如说，你可以选择 Nginx、HAProxy、LVS 等负载均衡软件，它们都能很好地支持双节点 +Keepalived 部署。这样当一个节点出了问题，另一个节点就可以自动顶上去，而且两个节点对外是共享一个虚拟 IP，所以节点的切换对外部是透明的。

这里，我们通过冗余和自动切换避免了单点的故障。

- 接入层 -> Web 应用

Web 应用通常是无状态的，，我们可以部署多个实例，很方便地通过水平扩展的方式，提升系统的处理能力。

接入层的负载均衡设备，可以通过各种算法进行多个 Web 实例的路由，并且对它们进行健康检测，如果某个实例有问题，请求可以转发到另一个实例进行处理，从而实现故障的自动转移。

通常情况下，我们还可以在接入层做限流，比如，在 Nginx 中设置每秒多少个并发的限制，超过这个并发数，Nginx 就直接返回错误。

这里，我们同时支持了 Web 节点的水平扩展、自动故障转移以及系统的可降级（限流）。

- Web 应用 -> 内部服务

服务通常也是无状态的，我们也可以通过部署多个实例进行水平扩展，支持服务实例的发现和负载均衡，比如在 Spring Cloud 中，我们就可以通过 Eureka 进行服务的自动注册和路由。

应用通常会访问多个服务，我们在这里可以做服务的隔离和熔断，避免服务之间相互影响。比如在 Spring Cloud 的 Hystrix 组件中，我们可以为不同服务配置不同的线程池，实现资源隔离，避免因为一个服务响应慢，而占用所有的线程资源；如果某个服务调用失败，我们可以对它进行熔断操作，避免无谓的超时等待，影响调用方的整体性能。

在应用和服务的内部，针对具体的功能，我们还可以做一些功能开关（这个在 eBay 有大量的落地）。

这里，我们同时支持了服务节点的水平扩展、自动故障转移以及系统的可降级（熔断和业务开关）。

- 访问基础资源

常见的资源包括关系数据库、缓存和消息系统。

关系数据库属于有状态服务，它的水平扩展没有那么容易，但还是有很多手段能够保障数据库的可用性和处理能力。

首先，我们可以做数据库的主从部署，数据库有成熟的  MHA 方案，支持主库故障时，能够自动实现主从切换，应用可以通过 VIP 访问数据库，因此这个切换过程对应用也是透明的。

另外，我们也可以通过物理的水平分库方式，对数据进行分片，这样就有多个主库支持写入。

# 13 | 高可用架构案例（一）：如何实现O2O平台日订单500万？

**项目背景介绍**

这是一个小程序点餐平台。这个项目服务于一家大型的餐饮公司，公司在全国有大量的门店，他们准备搞一个长期的大型线上促销活动，促销的力度很大：用户可以在小程序上先领取优惠券，然后凭券再支付 1 元，就可以购买价值数十元的套餐。

结合以往的经验，以及这次的促销力度，我们预计在高峰时，前端小程序请求将会达到每秒 10 万 QPS，并且预计首日的订单数量会超过 500 万。在这种高并发的情况下，我们为了保证用户的体验，系统整体的可用性要达到 99.99%。

这个点餐平台的具体架构如下。

![image-20220410223800721](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204102238844.png)

系统主要的调用过程如下。

1. 小程序前端通过 Nginx 网关，访问小程序服务端；
2. 小程序服务端会调用一系列的基础服务，完成相应的请求处理；
3. 订单服务接收到新订单后，先在本地数据库落地订单，然后通过 MQ 同步订单给 OMS 履单中心；
4. 门店的收银系统通过 HTTP 远程访问云端的 OMS 履单中心，拉取新订单，并返回取餐码给 OMS，OMS 再调用小程序订单服务同步取餐码；
5. 小程序前端刷新页面，访问服务端获得取餐码，然后用户可以根据取餐码到门店取餐或等待外卖。

**高可用系统改造措施**

这次活动的促销力度很大，高峰期流量将达到平时的数十倍，这就要求系统能够在高并发的场景下，保证高可用性。

在下面的系统架构图中，我标出了具体的改造点，主要有 10 处。

![image-20220410223918889](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204102239935.png)

1. 前端接入改造

这里的前端有两个，C 端的小程序和 B 端的门店收银系统。前端部分主要是对三个点进行改造，包括小程序端的 CDN 优化、Nginx 负载均衡，以及收银端的通信线路备份。

2. 应用和服务的水平扩展

针对小程序服务端的部署，我们把实例数从十几台提升到了 100 台，水平扩展它的处理能力。

3. 订单水平分库

下单高峰期，订单主库的写访问频率很高，一个订单会对应 6~7 次的写操作。改造后，我们有 4 个主库来负责订单数据写入。数据库的配置，也从原来的 8 核
16G 提升到了 16 核 32G。

这里的订单水平分库是通过订单 ID 取模进行分库。

4. 异步化处理

订单中心和后台 OMS 之间我们通过消息系统对它们进行了解耦。

还有在小程序服务端，在用户支付完成或者后台生成取餐码后，我们会以微信消息的方式通知用户，这个在代码中，也是通过异步方式实现的。

5. 主动通知，避免轮询

改造后，我们落地了消息推送中心，收银系统通过 Socket 方式，和推送中心保持长连接。

为了避免因消息推送中心出问题，导致收银系统拿不到新订单，收银系统还保持对 OMS 系统的轮询，但频率降低到了 1 分钟一次。

6. 缓存的使用

当收银系统向 OMS 拉取新订单时，OMS 不是到数据库里查询新订单，而是把新订单先保存在 Redis 队列里，OMS 通过直接查询 Redis，把新订单列表返回给收银系统。

每天凌晨，我们通过定时任务，模仿前端小程序，遍历访问每个商品数据，实现对缓存的预刷新，进一步保证缓存数据的一致性，也避免了缓存数据的同时失效，导致缓存雪崩。

7. 一体化监控

我们通过采集节点的状态数据，实时监测每个节点的健康程度，并且用红黄绿三种颜色，表示每个节点的健康状况。这里所有的节点都在一个页面里显示，包括 Web 应用、Redis、MQ 和数据库，页面也会体现节点之间的上下游关系。

**系统改造小结**

我们是如何知道要配置多少个节点，有没有达到预定的效果呢？

对于这个问题，我们的做法是，按照 10 万 QPS 和 99.99% 的可用指标要求，通过大量的压测来确定的。

# 14 | 高可用架构案例（二）：如何第一时间知道系统哪里有问题？

很多时候，我们可以从监控的角度来倒推系统的可用性设计。

**监控的分类**

系统的组成包括接入层、应用系统、中间件、基础设施这几个部分，那我们的监控也是针对这些部分来实施的。一般来说，监控可以分为 5 个层次，如下图所示：

![image-20220411223602506](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204112236627.png)

1. 用户体验监控：包括页面能否打开、关键接口的响应时间等等，用户体验监控一般结合前端的埋点来实现。
2. 业务监控：比如说订单数、交易金额等等。
3. 应用监控：比如接口在一段时间内的调用次数、响应时间、出错次数等等。（Cat、SkyWalking）
4. 中间件监控：比如数据库、缓存、Tomcat 等等，这些组件对应的是系统的 PaaS 层。这些中间件往往带有配套的监控系统，比如，RabbitMQ 就有自带的监控后台。
5. 基础平台监控：指的是对系统底层资源进行监控，如操作系统、硬件设备等等，这个层次的监控对应的是系统的 IaaS 层。（Zabbix）

**监控的痛点**

![image-20220411224032751](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204112240811.png)

1. 发现问题慢：业务监控的曲线一般 1 分钟更新一次，有时候因为正常的业务抖动，Monitor 还需要把这种情况排除掉。因此，他会倾向于多观察几分钟，这样就导致问题的确认有很大的滞后性。
2. 定位问题慢：系统节点多，大量的人需要介入排查，而且由于节点依赖复杂，需要反复沟通才能把信息串起来，因此很多时候，这种排查方式是串行或者说无序的。
3. 解决问题慢：当定位到问题，对系统进行调整后，验证问题是否已经得到解决，也不是一件很直观的事情，需要各个研发到相应的监控系统里去进行观察，通过滞后的业务曲线观察业务是否恢复。

**解决思路**

我们能不能把系统所有的监控信息自动关联起来，并且以一种直观的方式展示，让所有人一看就明白是哪里出了问题，以及出问题的原因是什么呢？

从这个思路出发，对系统的监控，我们需要做到两点：

1. 系统能够自动地判断每个节点是否正常，并直观地给出结果，不需要经过专业人员的分析。
2. 系统能够自动把各个节点的监控信息有机地串起来，从整体的角度对系统进行监控，不需要很多人反复地进行沟通。

在交通图上，通过红黄绿三种状态，实时地反映了每条道路的拥堵情况。

![image-20220411224204268](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204112242324.png)

这里有几个关键词：实时、直观、整体。

- 首先要实时，我们需要第一时间知道系统当前是否有问题
- 然后要直观，节点是否有问题，我们需要很直观地就能判断出来，就像交通图上的红黄绿颜色标识一样。
- 最后是整体，我们需要针对系统做整体监控，就像交通图一样，它是针对周边整体的道路情况进行展示，我们也需要把系统的各个节点放在一起，清晰地给出节点依赖关系。

所以，对照道路交通监控的思路，我们可以采取这样的监控方式：

- 首先，系统中的每个节点对应交通图的一条道路；
- 然后，节点的健康状况对应道路的拥堵情况，节点同样也有红黄绿三种不同的颜色，来展示该节点是否正常；
- 最后，节点之间的调用关系对应道路的方位关系。

**架构方案和效果**

根据前面的思路，我们设计了监控系统的整体架构，如下图所示：

![image-20220411224632444](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204112246530.png)

每个被监控的节点，均有对应的 Agent 负责采集健康数据。Agent 每隔 3s 采集节点数据，然后上报数据给 Monitor Service。Monitor Service 负责确定节点当前的状态并保存到数据库，这样就完成了节点健康状态的检测。

最后，前端 Dashboard 每隔 3s，拉取所有节点的状态，以红黄绿三种颜色在同一页面展示，同时还会显示具体的出错信息。

# 15 | 高可用架构案例（三）：如何打造一体化的监控系统？

今天我带你深入整体化监控系统的设计方案的内部设计。

**节点信息采集**

Agent 负责采集节点的健康数据，每隔 3s，主动访问一次。

![image-20220412225110316](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204122251017.png)

节点分为 4 类：Web 应用、Redis、MQ 和数据库。

- 对于 Redis 节点，Agent 通过 Jredis API，尝试连接 Redis 实例并进行简单的读写。
- 对于 MQ 节点，Agent 是通过 MQ API，来检测 MQ 节点是否有活跃的消费者在连接，同时检测队列积压的消息数量。
- 对于数据库节点，Agent 是通过 JDBC 去连接数据库，并对表进行简单的读写。

对于 Web 应用来说，Agent 采集的方式则稍微复杂一些，它会同时采集应用的功能和性能数据，具体包括最近 3s 的接口调用次数、接口平均响应时间、接口出错次数、节点的健康状态和错误消息。

比如下面这个例子：

```
请求：http://10.10.1.1/agent/check
返回信息：
"status":“warning",
"avg_time":“583.0",
"call_count":"10",
"error_count":"0",
"error_info":" orderListGet: current average time= 583.0, total average time = 109.84, 调用次数= 10"
```

Web 节点会预先提供一个 HTTP 接口，Agent 通过调用这个接口，返回当前 Web 实例最近 3s 的健康状态。

至于 Agent 如何部署，总的要求是，让 Agent 能够在 3s 内，完成所有节点的健康信息收集就可以了。

说完了节点信息的采集，下面我们来看下，这些节点要接入监控系统，都需要做些什么。

**接入监控系统**

对于 Redis、MQ、DB 这三类节点，接入监控系统只需要提供配置信息就可以了，无需额外的开发。而对于 Web 应用接入监控，我们需要对应用代码做些改造：

1. 针对每次接口调用，应用程序需要在接口代码中记录本次调用的耗时以及出错状况；
2. 应用程序需要汇总最近 3 秒的接口调用情况，根据规则，给出节点的健康状态；
3. 应用程序提供一个对外的 HTTP 接口，供 Agent 来获取上一步给出的健康状态。

为了方便 Web 应用的接入，监控系统开发团队提供了 SDK，SDK 帮助应用完成了最复杂的第二步工作。

实现思路为：SDK 的内部维护一个 HashMap 结构，它的 key 就是 Web 应用的各个接口名字，它的 value 是一个简单的对象，包含这个接口最近 3s 总的调用数量、总的出错次数和总的耗时等。当每次 Web 应用有接口调用时，我们在 HashMap 内部根据接口名字，找到对应的 value，然后增加这三个数值，就完成了接口调用数据的收集。

当 Agent 调用 HTTP 接口，拉取节点健康数据时，SDK 会计算节点的健康状况，具体规则如下：

- 如果最近 3s，接口调用没有发生错误，节点的健康结果就是正常；如果出错次数在 1 到 5 之间，健康结果就是警告；如果大于 5，健康结果就是错误。
- 如果最近 3s，接口响应时间超过正常值的 10 倍，健康结果就是错误；如果在 5 倍到 10 倍之间，健康结果就是警告，否则结果就是正常。

> 接口调用响应时间的正常值是怎么来的呢？
>
> 这个值不是预先设置的，我们知道，如果预先设置的话，这个数字很难确定。这里的正常值其实是 SDK 自动计算的，SDK会记录应用从启动开始到目前为止，接口的总耗时和总调用次数，然后得出平均的响应时间，作为接口调用的正常耗时（总调用次数和总耗时也记录在 HashMap 的 value 里）。

Web 应用的健康状态判断是结合了应用的功能和性能的，两者是“或”的逻辑关系，只要某一项有问题，健康结果就是有问题。比如说，最近 3s 接口功能没出错，但耗时是正常的 10 倍以上，SDK 就会认为节点的健康状态是错误的。

**前端信息展示**

我们把页面的展示内容分为三个层次，分组、应用和节点。一个页面代表一个系统，它包含多个分组，一个分组包含多个应用，一个应用包含多个节点（节点代表了一个具体的实例，有独立 IP）。

如下图所示，红色圈里的是各个分组，蓝色圈里是各个应用。我们可以很清晰地看到，“应用层”分组里的会员应用，会调用“依赖服务”分组里的四个服务。

![image-20220413231628830](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204132316973.png)

**库表设计**

监控系统的数据库表设计，主要的表有 3 张：

![image-20220413231720861](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204132317923.png)

1. 系统信息表，用来定义监控体系里有哪些系统，其中 Layout（布局）定义了该系统前端的布局方式。
2. 节点信息表，用来定义节点的配置信息，其中节点类型可选的值有 Web 应用、Redis、MQ、DB 等等，节点类型决定了节点健康信息的获取方式。其他字段用于 Agent 如何去连接节点，还有邮箱和手机用于节点出错时，相应的人可以接收报警信息。
3.  节点监控状态表，用来记录每个节点的最新健康状态，用于 Dashboard 显示。

# 16 | 高性能和可伸缩架构：业务增长，能不能加台机器就搞定？

在实际的工作当中，我们一般会比较关注业务功能的实现，而很少关注系统的性能，所以我们经常会面临以下这些挑战：

- 系统的 TPS 很低，只要流量一大，系统就挂，加机器也没用；
- 机器的资源利用率很低，造成资源严重浪费。

**常用的性能数据**

对于服务器来说，1ms 的时间其实不算短，它可以做很多事情，我在这里列了几个基础的性能数据，你可以把它们看做是系统性能的基线。

![下载](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204142219809.jpeg)

了解了这些常用的性能数据，你就能对性能建立一个直观的认识，有些时候，我们采取一些简单的手段就能提升系统的性能。比如说，如果磁盘的 IO 访问是瓶颈，我们只要用 SSD 磁盘来代替机械硬盘，就能够大幅度地提升系统的性能。

**高性能的策略和手段**

不同类型的节点，提升性能的方法是不一样的，概括起来，总体上可以分为三类。

- 加快单个请求处理

具体的做法主要有两种：优化处理路径上每个节点的处理速度。比如说，我们可以在代码中使用更好的算法和数据结构，来降低算法的时间和空间复杂度；可以通过索引，来优化数据库查询；也可以在高读写比的场景下，通过缓存来代替数据库访问等等。

并行处理单个请求。我们把一个请求分解为多个子请求，内部使用多个节点同时处理子请求，然后对结果进行合并。典型的例子就是 MapReduce 思想，这在大数据领域有很多实际的应用。

- 同时处理多个请求

当有多个外部请求进来时，系统同时使用多个节点来处理请求，每个节点分别来处理一个请求，从而提升系统单位时间内处理请求的数量。

除此之外，在同一个节点内部，我们还可以利用多进程、多线程技术，同时处理多个请求。

- 请求处理异步化

典型的例子就是通过消息系统对流量进行削峰，系统先把请求存起来，然后再在后台慢慢处理。

在实践中，我们需要根据实际情况，把三种手段结合起来。具体的处理手段要根据业务场景的不同综合考虑，在满足业务的基础上，争取对系统改造小，总体成本低。

**可伸缩的策略和手段**

我们可以动态地调整系统软硬件部署，在业务高峰期增加软硬件节点，在业务低谷期减少软硬件节点，这就是系统的可伸缩能力。

系统的可伸缩也有两种实现方式。

- 第一个是节点级别的可伸缩

对于无状态的节点，我们直接增减节点就可以了。比如说订单服务，白天我们需要 10 台机器来提供服务，到了半夜，由于单量减少，我们就可以停掉部分机器。

而对于有状态的服务，我们需要能够支持状态数据的重新分布。比如进行水平分库的时候，要从 4 个库增加到 8 个库，我们需要把原先 4 个库的数据，按照新的分库规则，重新分布到 8 个库中。如果这个调整对应用的影响小，那系统的可伸缩性就高。

- 第二个是系统级别的可伸缩

我们可以把多个处理节点打包在一起，形成一个处理单元。举个例子，针对交易场景，我们可以把商品浏览、加购物车、下单、支付这几个节点放一起，形成一个逻辑上的单元，在单元内部形成调用的闭环。

具体使用的时候，我们可以按照用户维度，来划分交易单元。比如说，让交易单元 A 处理用户 ID 对 2 取模为 0 的用户下单流程，交易单元 B 处理用户 ID 对 2 取模为 1 的用户下单流程。

这样，我们对一个整体的交易单元进行扩容或者缩容，每增加一个交易单元，就意味着同时增加商品浏览、加购物车、下单、支付 4 个节点，这 4 个节点的处理能力是匹配的。你可以参考下面的这张交易单元化的示意图：

![image-20220414224947590](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204142249662.png)

通过单元化处理，我们把相关的节点绑定在一起，同进同退，更容易实现系统的可伸缩。

**高性能和可伸缩架构原则**

- 可水平拆分和无状态

这意味着节点支持多实例部署，我们可以通过水平扩展，线性地提升节点的处理能力，保证良好的伸缩性以及低成本。

- 短事务和柔性事务

短事务意味着资源锁定的时间短，系统能够更好地支持并发处理；柔性事务意味着系统只需要保证状态的最终一致，这样我们就有更多的灵活手段来支持系统的高性能，比如说通过异步消息等等。

- 数据可缓存

缓存是系统性能优化的利器，如果数据能够缓存，我们就可以在内存里拿到数据，而不是通过磁盘 IO，这样可以大大减少数据库的压力，相对于数据库的成本，缓存的成本显然也更低。

- 计算可并行

如果计算可并行，我们就可以通过增加机器节点，加快单次请求的速度，提高性能。Hadoop 对大数据的处理就是一个很好的例子。

- 可异步处理

异步处理给系统的处理增加了弹性空间，我们可以利用更多的处理时间，来降低系统对资源的实时需求，在保证系统处理能力的同时，降低系统的成本。

- 虚拟化和容器化

虚拟化和容器化对系统的资源切分得更细，也就说明对资源的利用率更高，系统的成本也就更低。举个例子，我们可以为单个 Docker 容器分配 0.1 个 CPU，当容器的处理能力不足时，我们可以给它分配更多的 CPU，或者增加 Docker 容器的数量，从而实现系统的弹性扩容。

# 17 | 高性能架构案例：如何设计一个秒杀系统？

**背景和问题**

在 2014 年的时候，1 号店作为网上超市类电商，经常在线上举行各种大促活动。比如进口牛奶促销活动，每次促销的牛奶有几十万盒。这样的促销活动会在某个整点的时间进行开卖，往往短短几分钟内，所有牛奶就能售卖完毕。

这本质上是一种秒杀活动，一瞬间会有大量的用户流量涌入，流量可以高达平时的几十倍。而且和少量商品的秒杀不同，这些都是有效流量，最终会生成订单。

而在正常情况下，系统因为资源有限，只能处理 10% 的流量，无法处理剩下的 90% 流量，瞬间高并发的流量涌入，很大程度上会引起后台系统超时报错，导致用户下单不成功。这样一来，用户就会反复刷新页面，多次尝试下单。

最终的结果就是，系统往往由于过载，整体处理能力下降，甚至瘫痪，导致所有用户都无法购买。就像下图表示的一样：

![image-20220416205728887](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204162057033.png)

每次 1 号店要进行大促活动开始前，运营和技术人员会坐在一起，大家一起来预估活动的峰值流量，然后技术人员做评估，系统的哪些节点需要加机器，以及要加多少机器。但这样的做法其实存在几个问题：

- 首先，我们对峰值流量的预估以及要加多少机器都是拍脑袋的，和实际出入往往很大，一旦估计少了，系统同样会面临过载的风险；

- 其次，为了短暂的几分钟促销，我们需要增加大量的机器，事先要做很多的运维准备工作，不但浪费资源，而且效率很低；

- 最为关键的是，有些处理节点，系统不是通过加机器就能扩展处理能力的。

  > 比如商品库存数据库，下单时，我们需要扣库存，而为了防止库存更新冲突，我们需要锁定库存记录，导致系统的并发处理能力有限，这个问题单靠加机器是解决不了的。

**总体方案**

我们先来深入分析下业务场景。这个秒杀活动的特点是，在短期的 1~2 分钟内，用户流量很大，但只要促销的商品卖完，流量马上恢复常态。

对系统来说，短期内这么大的下单请求，后端如果实时处理，压力会非常大，但如果把这个处理时间延长到 10 分钟，后端是可以完成下单的。

对用户来说，商品优惠的力度这么大，他们关心的是能否买到，所以会愿意多等一段时间，而不是在页面上一次次点击下单，每次系统都提示下单失败。

基于这个分析，我们就可以利用异步处理的思路来应对秒杀活动。

我们先在前端接收用户所有的下单请求，并放在队列里；然后系统根据后端订单中心的实际处理能力，从队列里获取订单请求，再交给订单中心生成实际的订单。同时，系统告诉用户当前的处理进度，有多少订单排在 TA 的前面，TA 还要等多久。

> 比如说，有 20 万件的商品，每人限购一件，预计用户会在 2 分钟内完成下单，但用户能够接受系统在 20 分钟内完成订单处理。这样，系统只要保证每分钟能处理 1 万订单就行。
>
> 而如果不采取排队的方式，系统就需要每分钟处理 10 万订单，它的压力就会提升一个数量级。

基于排队的思路，系统总体架构设计如下图所示：

![image-20220416210136617](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204162101688.png)

在这个架构中，我们在前台和后台下单系统之间，新增了排队系统，它包括排队区和处理区两个部分。系统整体的处理过程是这样的：

1. 用户在商品详情页提交订单后，这个订单会作为预订单进入排队区，同时排队系统会返回用户一个排队编号，这个编号用于跟踪后续的订单处理进度；
2. 用户被引导到一个等待页，这个页面会根据排队号，定时地查询排队系统，排队系统会返回预订单在队列中的位置信息，包括它前面还有多少未处理的预订单，以及后台系统大概还要多久会处理这个预订单；
3. 在排队系统的处理区，有很多消费者，它们依次从排队区的队列里获取预订单，然后调用后台下单系统生成实际的订单；
4. 随着预订单变成正式的订单，队列里的预订单会逐渐变少，如果当前的预订单已经从队列里被移除了，用户的等待页就会检测到这个情况，页面自动跳转到订单完成页，这就和常规的购物流程一样了，用户进行最后的支付，最终完成整个前台下单过程。

下面是一张用户等待页的效果图，你可以直观地了解秒杀系统的用户体验。

![image-20220416210305334](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204162103408.png)

**内部设计**

- 队列的技术选型

针对队列的技术选型，排队系统使用的是 Redis，而不是 MQ。Redis 除了和 MQ 一样支持消息的先进先出以外，我们还可以获取队列的长度，以及通过排队号获取消息在队列中的位置，这样我们就可以给前端反馈预订单的处理进度。

- 队列与商品的关系

对于秒杀场景来说，一个订单只能包含一个商品，这里我们为每个秒杀商品提供一个单独的队列，这样就可以分散数据在 Redis 中的存取，多个队列可以提供更好的性能。

- 队列的调度问题

比如说，某个秒杀商品的队列很长，消费者会优先从这个队列拿预订单，从而避免用户等待太长的时间。

- 队列长度

关于队列长度，为了保证用户能够买到商品，我们并不是把所有前台的下单请求都会放到队列里，而是根据参与活动的秒杀商品数量，按照 1:1 的比例，设置队列初始长度，这样就保证了进入队列的请求最终都能生成订单。

> 这个可用队列长度会随着预订单进入队列，不断地减少，当数值变为 0 时，下单前台会拒绝接受新请求进入队列，直接反馈用户下单失败。
>
> 当然，如果后台订单生成异常或用户取消订单后，可用队列长度会增加，前台会重新开放预订单进入队列。

- 更多优化：建立活动库存

如果运营人员在后台上架商品的时候，设置这是一个秒杀商品，那么从详情页开始，系统就会引导用户走秒杀流程，否则就走常规购物流程。

![image-20220416213742003](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204162137097.png)

此外，对于秒杀活动来说，参与活动的商品种类是有限的，但这些商品库存的扣减非常频繁，因此我们建立了活动库存的概念，把少量参与促销的商品种类单独放在一个库里，避免和大量常规的商品放在一起，这样也大幅度地提高了库存数据库的读写性能。

**总结**

我们巧妙地通过请求的异步化处理，对流量进行削峰，从而保证了系统的高性能。这里我们不需要增加太多的机器。

不过值得注意的是，这种方式比较适合瞬时有高并发流量的场景。如果订单高峰会持续一段较长的时间，而用户对订单处理又有比较高的时间要求，那就不适合采用这种异步削峰的方式。

举个例子，外卖订单的午高峰通常会持续两个小时，而用户普遍期待订单半小时能够送达。对于这种情况，我们就需要正面应对高峰流量，比如通过水平扩展各个节点，提升系统的处理能力。这也要求系统能够做到弹性伸缩，高效地支持资源的缩容或扩容，节省成本。

# 18 | 可伸缩架构案例：数据太多，如何无限扩展你的数据库？

今天，我会通过 1 号店订单水平分库的实际案例，和你具体介绍如何实现系统的可伸缩。

**问题和解决思路**

2013 年，随着 1 号店业务的发展，每日的订单量接近 100 万。这个时候，订单库已有上亿条记录，订单表有上百个字段，这些数据存储在一个 Oracle 数据库里。

随着单量的增长以及在线促销的常态化，单一数据库的存储容量和访问性能都已经不能满足业务需求了，订单数据库已成为系统的瓶颈。所以，对这个数据库的拆分势在必行。

- 垂直分库：就是数据库里的表太多，我们把它们分散到多个数据库，一般是根据业务进行划分，把关系密切的表放在同一个数据库里。
- 水平分库：某些表太大，单个数据库存储不下，或者数据库的读写性能有压力。我们把一张表拆成多张表，每张表存放部分记录，分别保存在不同的数据库里。

当时，1 号店的问题不是表的数量太多，而是单表的数据量太大，读写性能差。

**分库策略**

我们先来讨论一下水平分库的具体策略，包括要选择哪个分库维度，数据记录如何划分，以及要分为几个数据库。

- 分库维度怎么定？

首先，我们需要考虑根据哪个字段来作为分库的维度。

这个字段选择的标准是，尽量避免应用代码和 SQL 性能受到影响。具体地说，就是现有的 SQL 在分库后，它的访问尽量落在单个数据库里，否则原来的单库访问就变成了多库扫描，不但 SQL 的性能会受到影响，而且相应的代码也需要进行改造。

我们先收集所有 SQL，挑选出 WHERE 语句中最常出现的过滤字段，比如说这里有三个候选对象，分别是用户 ID、订单 ID 和商家 ID，每个字段在 SQL 中都会出现三种情况：

1. 单 ID 过滤，比如说“用户 ID=？”；
2. 多 ID 过滤，比如“用户 ID IN(?,?,?)”；
3. 该 ID 不出现。

最后，我们分别统计这三个字段的使用情况，假设共有 500 个 SQL 访问订单库，3 个候选字段出现的情况如下：

![image-20220417223112170](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204172231338.png)

从这张表来看，结论非常明显，我们应该选择用户 ID 来进行分库。

在项目中，我们分析了 Top15 执行次数最多的 SQL （它们占总执行次数 85%，具有足够代表性），按照执行的次数，如果使用用户 ID 进行分库，这些 SQL 85% 会落到单个数据库，13% 落到多个数据库，只有 2% 需要遍历所有的数据库。所以说，从 SQL 动态执行次数的角度来看，用户 ID 分库也明显优于使用其他两个 ID 进行分库。

- 数据怎么分？

我们如何把记录分到各个库里呢？一般有两种数据分法：

1. 根据 ID 范围进行分库，比如把用户 ID 为 1 ~ 999 的记录分到第一个库，1000 ~ 1999 的分到第二个库，以此类推。
2. 根据 ID 取模进行分库，比如把用户 ID mod 10，余数为 0 的记录放到第一个库，余数为 1 的放到第二个库，以此类推。

这两种分法，各自存在优缺点，如下表所示：

![image-20220417223218255](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204172232325.png)

在实践中，为了运维方便，选择 ID 取模进行分库的做法比较多。同时为了数据迁移方便，一般分库的数量是按照倍数增加的。

比如说，一开始是 4 个库，二次分裂为 8 个，再分成 16 个。这样对于某个库的数据，在分裂的时候，一半数据会移到新库，剩余的可以不用动。与此相反，如果我们每次只增加一个库，所有记录都要按照新的模数做调整。

- 分几个库？

分库数量，首先和单库能处理的记录数有关。一般来说，MySQL 单库超过了 5000 万条记录，Oracle 单库超过了 1 亿条记录，DB 的压力就很大（当然这也和字段数量、字段长度和查询模式有关系）。

具体分多少个库，需要做一个综合评估，一般初次分库，我建议你分成 4~8 个库。在项目中，我们拆分为了 6 个数据库，这样可以满足较长一段时间的订单业务需求。

**分库带来的问题**

- 分库路由

分库从某种意义上来说，意味着 DB Schema 改变了，必然会影响应用，但这种改变和业务无关，所以我们要尽量保证分库相关的逻辑都在数据访问层（DAL）进行处理，对上层的订单服务透明，服务代码无需改造。

对于单库访问，比如查询条件已经指定了用户 ID，那么该 SQL 只需访问特定库即可。此时应该由 DAL 层自动路由到特定库，当库二次分裂时，我们也只需要修改取模因子就可以了，应用代码不会受到影响。

对于简单的多库查询，DAL 层负责汇总各个分库返回的记录，此时它仍对上层应用透明。

对于带聚合运算的多库查询，比如说带 groupby、orderby、min、max、avg 等关键字，可以让 DAL 层汇总单个库返回的结果，然后由上层应用做进一步的处理。

> 这样做有两方面的原因，一方面是因为让 DAL 层支持所有可能的聚合场景，实现逻辑会很复杂；
>
> 另一方面，从 1 号店的实践来看，这样的聚合场景并不多，在上层应用做针对性处理，会更加灵活。

DAL 层还可以进一步细分为底层 JDBC 驱动层和偏上面的数据访问层。如果我们基于 JDBC 层面实现分库路由，系统开发难度大，灵活性低，目前也没有很好的成功案例。

在实践中，我们一般是基于持久层框架，把它进一步封装成 DDAL（Distributed Data Access Layer，分布式数据访问层），实现分库路由。1 号店的 DDAL 就是基于 iBatis 进一步封装而来的。

- 分页处理

假设我们要按时间顺序展示某个商家的订单，每页有 100 条记录，由于是按商家查询，我们需要遍历所有数据库。假设库数量是 8，我们来看下水平分库后的分页逻辑：

- 如果是取第 1 页数据，我们需要从每个库里按时间顺序取前 100 条记录，8 个库汇总后共有 800 条，然后我们对这 800 条记录在应用里进行二次排序，最后取前 100 条；
- 如果取第 10 页数据，则需要从每个库里取前 1000（100*10）条记录，汇总后共有 8000 条记录，然后我们对这 8000 条记录进行二次排序后，取第 900 到 1000 之间的记录。

在分库情况下，对于每个数据库，我们要取更多的记录，并且汇总后，还要在应用里做二次排序，越是靠后的分页，系统要耗费更多的内存和执行时间。

那么，我们如何解决分库情况下的分页问题呢？如果是为前台应用提供分页，我们可以限定用户只能看到前面 n 页；分库设计时，一般还有配套的大数据平台负责汇总所有分库的记录，所以有些分页查询，我们可以考虑走大数据平台。

- 分库字段映射

分库字段只有一个，比如这里，我们用的是用户 ID。但在订单服务里，根据订单 ID 查询的场景也很多见，如果不做特殊处理，系统会盲目查询所有分库，从而带来不必要的资源开销。

所以，这里我们为订单 ID 和用户 ID 创建映射，保存在 Lookup 表里，我们就可以根据订单 ID，找到相应的用户 ID，从而实现单库定位。

Lookup 表的记录数和订单库记录总数相等，但它只有 2 个字段，所以存储和查询性能都不是问题；这个表在单独的数据库里存放，在实际使用时，我们可以通过分布式缓存，来优化 Lookup 表的查询性能；此外，对于新增的订单，除了写订单表，我们同时还要写 Lookup 表。

**整体架构**

最终的 1 号店订单水平分库的总体技术架构如下图所示：

![image-20220418215907347](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182159068.png)

上层应用通过订单服务访问数据库；

分库代理实现了分库相关的功能，包括聚合运算、订单 ID 到用户 ID 的映射，做到分库逻辑对订单服务透明；

Lookup 表用于订单 ID 和用户 ID 的映射，保证订单服务按订单 ID 访问时，可以直接落到单个库，Cache 是 Lookup 表数据的缓存；

DDAL 提供库的路由，可以根据用户 ID 定位到某个库，对于多库访问，DDAL 支持可选的多线程并发访问模式，并支持简单的记录汇总；

Lookup 表初始化数据来自于现有的分库数据，当新增订单记录时，由分库代理异步写入。

这样的架构如何安全落地呢？订单表是系统的核心业务表，它的改动很容易导致依赖订单服务的应用出现问题。我们在上线时，必须谨慎考虑。

- 首先，实现 Oracle 和 MySQL 两套库并行，所有数据读写指向 Oracle 库，我们通过数据同步程序，把数据从 Oracle 拆分到多个 MySQL 库，比如说 3 分钟增量同步一次。
- 其次，我们选择几个对数据实时性要求不高的访问场景（比如访问历史订单），把订单服务转向访问 MySQL 数据库，以检验整套方案的可行性。
- 最后，经过大量测试，如果性能和功能都没有问题，我们再一次性把所有实时读写访问转向 MySQL，废弃 Oracle。

这里，我们把上线分成了两个阶段：第一阶段，把部分非实时的功能切换到 MySQL，这个阶段主要是为了验证技术，它包括了分库代理、DDAL、Lookup 表等基础设施的改造；

第二阶段，主要是验证业务功能，我们把所有订单场景全面接入 MySQL。1 号店两个阶段的上线都是一次性成功的，特别是第二阶段的上线，100 多个依赖订单服务的应用，通过简单的重启就完成了系统的升级，中间没有出现一例较大的问题。

# 19 | 综合案例：电商平台技术架构是如何演变的？

**单体系统**

第一代的电商系统是一个单体架构，所有的代码都打包在一个应用里，部署的时候会有多个实例，我们通过负载均衡，把用户请求分发到具体的实例中。

![image-20220418221947262](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182219349.png)

这里的问题是，单体应用的所有代码都放在一起，代码编译需要很长时间，应用启动也需要很长时间，并且代码相互依赖，开发效率低，并行开发困难。随着单体应用的体量越变越大，这些问题也越来越突出。

**SOA 架构**

针对单体应用体量过大带来的问题，我们对系统进行拆分。

![image-20220418222218497](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182222585.png)

但这里的问题是，内部服务通过中心化的负载均衡进行访问，中心化的负载均衡增加了服务的调用时间。此外，服务调用的频率很高，每秒可能有上百万次，导致了负载均衡的连接能力不够。而且负载均衡是单点，如果它出了问题，很容易引发系统整体的可用性问题（即使负载均衡是多实例，当系统流量很大时，也会因为某台负载有问题，导致其他节点压力增大而引起雪崩效应）。

**服务调用去中心化**

![image-20220418222238594](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182222685.png)

现在，我们解决了服务调用的问题，但随着业务量逐渐变大，数据表越来越多，数据量也越来越大，单个数据库（比如 Oracle）的性能和储存容量已经无法满足需求了。这个时候，我们就需要对数据库进行改造，提升它的处理能力。

**垂直分库**

![image-20220418222323561](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182223647.png)

垂直分库后，每个数据库都是单实例。随着业务的发展，和原来系统只有单个数据库类似，现在交易系统也只有一个数据库，它的性能和容量还是有问题，并且数据库单实例也带来了可用性的问题，如果数据库挂了，相应的系统也就不可用。

**水平分库及高可用部署**

![image-20220418222347101](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182223171.png)

当系统体量发展到了一定程度，我们又碰到了新的问题：单个机房的服务器不够用，无法在同一个机房找到更多的机器部署交易系统和账户系统。

**多机房部署**

![image-20220418222422839](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182224911.png)

这里产生了跨机房访问的问题：首先，我们只有一个服务注册中心，服务实例一部分部署在老机房，一部分部署在新机房，对于服务调用者来说，它会同时访问新旧机房的服务实例；其次，数据库部署在老机房，新机房的应用会访问旧机房的数据库。

跨机房访问的网络延时在数十毫秒到数百毫秒之间，是机房内部通信耗时的上千倍，这会对应用的性能产生很大影响，而且跨机房的网络可用性也经常是一个问题。

**服务调用本地化**

为了避免服务的跨机房访问，我们在新机房也单独部署了服务注册中心，让每个机房的服务注册到同机房的注册中心。这样，客户端的服务调用会路由到同机房的服务端，实现了服务调用的本地化，大大降低了跨机房通信带来的延时和不可用性问题。

![image-20220418222458086](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182224173.png)

这时，随着业务越来越复杂，新的问题又来了：交易系统会依赖很多周边服务。比如下单后，我们需要给用户送积分，交易系统会同步调用积分服务。但是同步调用积分服务，一方面会影响下单的性能，另一方面如果积分服务不可用，会导致核心的下单功能失败。

**依赖分级管理**

对于外部服务依赖的可用性问题，我们的解决办法是，针对这些外部依赖进行分级管理，根据依赖功能的重要性不同，把它们分为强依赖和弱依赖。

- 对于强依赖，我们实时同步调用，比如在用户下单时调用库存服务，由于库存非常重要，必须实时扣减，如果调用库存服务失败，下单也失败。
- 对于大量的弱依赖，我们以异步消息的方式进行信息同步，比如对于积分服务，可以通过柔性事务来保证数据的最终一致性，这样大大提升了核心系统的性能和可用性。

![image-20220418222539802](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182225890.png)

不过，这里存在的问题是，新机房的交易系统和账户系统都在访问老机房的数据库，有跨机房数据库访问的性能问题，以及老机房整体故障带来的可用性问题。比如说，机房断电，通信光纤有问题或者发生自然灾害，导致老机房整体不可用，这就会导致所有系统都不可用。

**多机房独立部署**

针对机房整体不可用的问题，解决方案是，我们在多个机房做对等的部署，这样每个机房的系统可以形成内部闭环，包括服务、注册中心和数据库，机房之间不产生直接的相互依赖，从而实现了机房级别的水平部署。

![image-20220418222602337](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202204182226430.png)

如果系统的单元化做得完善，我们还可以进一步支持虚拟机房的概念，一个物理机房可以部署多个虚拟机房，每个虚拟机房包含了一个完整的系统。通过多机房独立部署，我们极大地提升了系统的可用性、处理能力和可伸缩性，可以应对系统面临的各种异常情况。
