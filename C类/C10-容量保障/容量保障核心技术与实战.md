# 开篇词 | 互联网时代，人人肩负容量保障的职责

在我的职业生涯中，能够非常深刻地感受到，容量保障对于一家互联网公司的重要性，因为几乎每时每刻我都在回答这些问题：

- 我负责的软件系统目前运行的很好，但是公司业务增长迅猛，如果访问量增加 2 倍，系统还能支撑吗？
- 如果无法支撑 2 倍的访问量，哪些服务会首先成为瓶颈？
- 这些服务如果采取扩容措施，需要扩容多少量？
- 大规模促销活动场景下，容量风险如何识别和预防？

我在多个场合进行容量保障分享时，也经常被问及这样的问题：

- 我们一直在做性能测试，为啥服务容量还是老出问题？
- 容量保障，有没有套路可循？
- 我们公司规模不大，没有专人去做容量保障，有没有成本低点的办法？
- 我公司规模不大，业务也没有什么大促场景，需要做容量保障吗？

**到底什么是容量保障?**

容量保障，就是用各种方法保证软件系统的容量充足，预防容量隐患的重要工作。

容量保障对于系统稳定性至关重要，如果一辆货车核载 80 吨，而我们塞进了 100 吨的货物，后果可想而知。

**容量保障难不难？**

互联网场景下的容量保障工作是一项系统性工程，它的难点主要体现在以下几个方面。

1. 容量的不确定性：一辆货车在交付时已经标注了核载重量，而互联网服务的容量受服务器资源、架构设计、网络传输状况和业务场景等多种条件制约，会呈现出不同的容量表现，很难得到确定解。
2. 容量评估的复杂性：随着微服务架构的日益盛行，服务链路变得越来越复杂，任何一个环节出现容量瓶颈都有可能放大到整条链路，这给容量评估工作带来了难度。
3. 容量测试的不准确性：容量测试的场景需要尽可能逼近真实情况，还需要保证被测服务的环境（服务资源、规模、配置等）与真实环境对等，但实际上受制于各种原因，我们很难做到完全仿真，因此容量测量的准确性也是一个挑战。
4. 此外，容量保障还会牵扯到成本管理的问题，这也是一个难点。

说了那么多难点，那么如何将它们变得不难呢？这就是我的这个专栏希望带给你的价值。

**课程是如何设计的?**

在这次的专栏中，我将从技术视角出发构建一个容量保障体系化的大图，覆盖容量保障工作的方方面面，逐个击破，尽可能全面地展现容量保障各项技术的全貌。具体来说，会有以下三个部分。

基础篇：我将以容量保障工作的时间轴为主线，分别就目标、测量、分析、治理这几大工作展开，积累容量保障的通用方法，帮助你完成基础入门。

进阶篇：我将分几个独立专项话题，对容量保障工作中的一些前沿技术进行深入剖析，包括全链路压测、分布式压测平台的研发工作，以及 AI 预测容量、云原生下的容量保障新趋势等。这其中部分话题在业界甚至是第一次公开，非常值得学习。

案例篇：从案例场景出发，介绍双 11 大促场景下的容量保障工作如何做好，及小公司如何建立容量保障体系，并对容量保障组织建设给出我的建议。

在这里，我先为你总结一套较为适合互联网场景的容量保障方法论，如下图所示。

![image-20241104231431875](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411042314907.png)

先从“日常容量”和“大促容量”的目标出发，拆分出三个入口：

- 计划事件：事先能够预知的新功能或大促活动
- 突发事件：事先无法预知的紧急事件
- 日常事件：常态化的容量表现

再自上而下拆解出具体的策略（工作项、工具、规范、案例等），每一项策略再做具体细分，形成一个有机的整体。

当然，这套方法论未必适合所有的场景和业务形态，但我认为，即便是在一个全新的领域，它也可以帮助你在最短的时间内，建立一套有效的容量保障体系。更重要的是，它提供了一种核心的思维方式。

# ==基础篇==

# 01 | 容量保障的目标：容量保障的目标是什么？该如何度量？

如果我们面对的是企事业单位的某个内部系统，有着非常稳定的用户规模和几乎不变的产品功能，那么容量保障就是基于固定用户量的一次性保障工作。相反，如果是大型电商系统，业务场景有明显的流量峰值，且经常举办大促活动，容量保障就是一部“跌宕起伏的连续剧”。

**容量保障的目标是什么？**

总结一下其实就两句话：

- 第一，容量规划。以尽可能小的成本确保系统当前和未来的容量充足；
- 第二，容量治理。解决已知的容量问题，预防未知的容量问题。

在控制成本的基础上，我们要保障服务容量充足，即服务的各项资源消耗和业务指标保持在一个相对安全的范围内，这个范围可以是推算出来的，也可以是通过容量测试验证出来的，亦可以是真实流量体现出来的，我们将其称之为“安全水位”。

分布式系统中充满了不确定性，网络可能抖三抖，硬盘可能崩一崩，我们一方面要尽可能在这种不可靠的环境下预防容量问题的发生，又要在出现容量问题时，有能力在短时间内消除影响，甚至是全自动的进行止损，这一点直接影响着服务可用性和用户体验。

**容量保障目标的量化**

如果公司将容量保障的任务交给你来完成，你怎么证明自己的工作完成得好不好呢？这时候，你就需要去量化目标，用数据说话。

那么，容量保障工作中有哪些关键的量化指标呢？

1、服务等级协议（SLA）

通俗地说，SLA 就是对服务可用性的一个保证。

举个具体的例子，我们要求系统整体可用性 SLA 为 4 个 9（99.99%），即每年不可用时长≤52.56 分钟。基于这个整体 SLA 要求，并综合考虑历年容量问题对服务可用性的影响比例（比如占比为1/5），最终设定容量问题造成的可用性损失不高于 10 分钟（52.26 / 5≈10 分钟），这就是一个明确的目标，基于这个目标拆解策略是可衡量的。

再比如，我们将交易链路下单接口的成功率≥95% 作为 SLA 的一部分，并且承诺低于该成功率的时长不超过 1 分钟，这就是一个容易理解且可测量的 SLA，通过对下单接口的监控就可以观测。交易链路的容量问题有导致下单成功率下跌的可能性，因此作为容量保障的目标也是合理的。

![image-20241105231650520](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411052316639.png)

2、QPS/TPS

QPS（Queries per Second）指的是每秒查询率，是一台服务器每秒能够响应的查询次数，即 1 秒内完成的请求数量，一般针对读请求居多。

TPS（Transactions per Second）指的是每秒处理的事务数，一般针对写请求居多。

QPS/TPS 是容量保障目标中最常见的指标，我们通常说“系统容量是否足够”，一般就是指系统或服务能否在可接受的响应时间和成功率下支撑目标 QPS/TPS。

3、用户体验

第三个关键指标是用户体验。有些容量问题尽管没有影响可用性，但会导致用户操作时响应延迟，页面打开缓慢等体验问题。

不过，用户体验问题的定性是相对困难的，一种手段是将客户投诉或内测版本反馈作为一个维度去跟踪。另外，绝大多数用户体验是可以与系统指标或业务指标挂钩的，这些指标就可以作为目标的一部分。比如，有用户反馈某个操作等待时间特别长，其涉及的接口背后的服务器 CPU 利用率、内存利用率、响应时间、调用的消息队列延迟等信息，就都可以作为参考维度。

# 02 | 容量测试与验证：怎样科学实施容量测试？

传统对容量测试的认知都希望能够获得一个瓶颈点，这是以压测的视角来看待它的。但绝大多数时候，我们都是根据预先制定的容量目标，通过对服务施压来观察和验证服务能否承载这一目标，并不是非要压出极限值。

阿里前任 CTO 行癫在 2018 年双 11 启动会上说过一句话：“容量测试是验证手段，不是测试手段”。 换句话说，我们应该先努力设计和建造出满足容量要求的服务，再通过容量测试去验证它，而不是靠容量测试去反复探测服务容量瓶颈，再去不停地优化服务或扩容。我认为这才是对容量测试的现代化理解。

下面我们就来具体展开，看一下容量测试该怎么做。

**确定容量测试的范围**

在进行容量测试前，我们先要弄清测试的范围。

一种比较经济的方式是风险驱动，即针对容易产生容量风险的服务重点考虑进行容量测试。那么，问题来了，哪些服务最容易出现容量风险呢？下图为你做了一定的概括，我来展开讲解。

![image-20241125225117999](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411252251059.png)

第一，关键路径上的核心服务肯定是重点保障对象。倒不是说这些服务就一定会有容量风险，而是一旦出现风险，影响会比较大。

第二，有明显流量峰值特征的服务，比如高峰期和低峰期的流量差异非常大的服务，或者是经常举办活动会造成流量突增的服务。这种巨大的流量差异容易引发服务容量风险。

第三，对响应时间敏感的服务，有些底层服务经常被上游服务在同一次请求中调用好几次，一旦响应时间上升，汇聚到上游服务的总响应时间会被放大好几倍，这种服务的容量就要特别小心。

第四，占用资源大的服务，比如占用大量带宽、占用大量内存等，容易造成资源耗尽的服务，就容易引发容量问题。

另外，除了关注容易产生容量风险的服务，对于历史上曾经发生过容量事故的服务、目前高峰期已经存在容量隐患的服务、新上线对容量情况未知的服务，也都要重点进行容量测试。

**科学实施容量测试**

确定了容量测试的范围，我们具体看一下如何实施容量测试。下图就是实施容量测试的全局流程图，基于这张图，我来具体展开每一个重点步骤。

![image-20241125225723945](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411252257993.png)

1. 测试方案设计

测试方案是写给自己，更是写给团队看的，这是你将信息通过一种形式传达给外部的过程，缺少这一过程，随之而来的就是潜在的误解和信息不对称，是有非常大的隐患的。

这里给出一个较为通用的容量测试方案设计模板。

![image-20241125223413753](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411252234847.png)

2. 测试方案评审

为了避免评审过程枯燥乏味，我们提倡内容正式、形式轻松、集中精力、高效评审。当时在我的办公楼层，有一台可移动的电视机，我们把这台电视机推到茶水间门口的沙发边上，每人拿上一瓶饮料就开始评审了，除了主讲人以外其他人不允许带电脑，评审在一小时内完成，偶尔有超时的，另行预约时间。

3. 测试准备

测试方案确认无误后，容量测试人员就可以开始着手进行准备工作了：根据评审过的场景撰写测试脚本，准备测试数据。准备完毕后，调试脚本和数据，确保能够正常执行，服务无异常。

4. 测试执行

无论使用何种测试工具，测试执行的流程和规范都是类似的，下面给出一个较为通用，且比较安全的推荐流程。

![image-20241125223839482](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411252238528.png)

由于我们事前并不知道系统实际是否能够承载预估的容量，所以容量测试是一种较为高危的验证过程。我再列举一些常见的容易导致测试过程影响线上业务的情况，你一定要多加注意：

- 直接压到容量预估峰值，风险极大；
- 只进行测试，不观察监控，出了问题也不知道；
- 单次测试时间过长，不符合实际情况；
- 没有止损预案，出了问题手忙脚乱；
- 对目标业务不熟悉，尤其是上下游链路，把生产环境作为试验场。

5. 测试反馈

容量测试结束后，要有明确结论，总结测试过程中的各项指标和数据，与各方确认数据结论是否正常以及是否达到预期，编写测试报告，输出结论。

6. 持续跟进

容量测试不是单纯的测完就好，暴露的问题需要有效跟进，并在一定时间内跟踪解决，改进后确定时间再次进行验收，确保改进措施有效。

**另一种容量测试：基线容量测试**

有一种方式可以让我们在测试环境以较低的成本先“定性”的识别出容量差异，以便提前发现可能存在的容量隐患，这种方式称之为基线容量测试。

基线容量测试在线下测试环境就能完成，具体的做法是，我们需要按照与线上相同的部署方式搭建这套测试环境（下称“基线环境”），包括所有的中间件和网络设施，不过资源规模可以等比例减少。之后，将当前各服务的主干版本部署在基线环境上，并通过容量测试的方式获取容量指标记录备案，这些指标就称之为“基线指标”。

# 03 | 容量指标分析经典5问：响应时间真的是越短越好吗？



# 04 | 容量治理的三板斧：扩容、限流与降级

找到问题以后，我们需要排除这些容量风险，确保服务的稳定性，这就是容量治理需要做的工作了。下面，我们就来认识一下三个常见的容量治理手段：扩容、限流和降级。

**扩容的实践要点**

在服务容器化盛行的当下，拉起一个新服务实例，往往只需要秒级时间，扩容的成本得到了有效的降低，能够快速消除容量风险。我对扩容的态度是：鼓励将快速扩容作为应急手段，但作为容量治理手段要谨慎，警惕无脑扩容和滥用扩容。

> 不要无脑扩容

在实际工作中，很多业务研发一遇到自己的服务容量不足，第一个念头就是扩容，服务本身的优化工作，包括异步处理、读写分离、增加缓存、SQL 调优等等，往往会被忽略，这是有很大风险的。

首先，容量保障是要考虑成本的，如果纯粹依靠扩容去支撑性能低劣的服务，浪费的是大量的资源和金钱。其次，扩容也很容易触碰到边际递减效应，也就是说，服务资源达到一定规模后，再往上扩容的代价会大幅上升。

> 要关注对底层资源的影响

除了避免无脑扩容，我还要提醒你注意的是，扩容不能只关注服务本身的资源占用情况，还应同时关注对底层资源的影响，如：数据库资源、中间件资源等。

例如，在微服务体系中有一项服务发现机制，它的一种实现方式是，由一个注册中心建立对每个服务实例的长连接，并维护一个服务状态列表，这样一旦服务状态发生变化，注册中心能够第一时间感知到并对服务状态列表进行更新。当我们对服务进行扩容时，实际上就是增加了服务实例，这会产生更多的长连接。因此在这种服务发现模式下进行扩容时，注册中心的容量也需要同步考虑。

> 扩容要点

那我们在扩容时要考虑哪结点呢？一种通用的做法是，先梳理出被扩容服务的调用链路，看一看流量经过哪些地方，分析一下这些地方会不会受到扩容的影响，再去采取相应措施。

总结一下扩容的实践要点，首先，要建立服务性能优化胜过简单扩容的意识，努力通过性能优化腾出容量，避免不经思考直接扩容。其次，扩容要联动系统整体资源共同规划，不能只关注服务资源。

**限流的实践要点**

即便进行了严密的容量规划和系统优化，我们依然无法保证线上流量一定百分百符合既定的预测范围，因为总会有这样那样的突发事件发生。那么，在提前设置限流时，我们应该选择什么样的限流策略，以及在什么位置进行限流呢？

> 限流策略

首先，从限流策略的角度，可以将常见的策略形象地归纳为“两窗两桶”，分别有：固定窗口、滑动窗口、漏桶算法和令牌桶算法。首先要与你分享的经验是，限流策略的选择和业务场景应当是高度挂钩的，不能想当然觉得复杂的策略就一定好。

上述四个限流策略中，与业务场景紧密相关的三大流量控制方式，分别是：流量整形、容忍突发流量和平滑限流，它们的含义如下：

- 流量整形： 指不管流量到达的速率多么不稳定，在接收流量后，都将其匀速输出的过程，即“乱进齐出”。
- 容忍突发流量： 指的是限流策略允许流量在短时间内突增，且在突增结束后不会影响后续流量的正常限流。
- 平滑限流： 指的是在限流周期内流量分布均匀，比如限制 10 秒内请求次数不超过 1000，平滑限流应做到分摊到每秒不超过 100 次请求。反之，不平滑限流有可能在第 1 秒就请求了 1000 次，后面 9 秒无法再发出任何请求。

不同限流策略对流量控制方式的具体支持情况如下：

![image-20241112231022185](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411122310298.png)

固定窗口无法容忍突发流量，但它实现简单，资源消耗少，如果你的应用服务流量是平缓增长的形态，也没有流量整形的需求，这时采用固定窗口策略进行限流就不失为一种合理又经济的选择。如果你的应用服务经常需要应对诸如大促场景这样的突发流量，那么使用令牌桶算法进行限流往往会更适合，当然，这时你也得接受令牌桶策略实现的高复杂度。

总之，针对每个限流策略的特点，在具体业务场景合理使用，才能发挥它最大的价值。

> 限流位置

接下来我们将视线切换到另一个维度，从限流位置的视角来探讨限流实践，这里想说明的核心理念是：==良好的限流应该是分层次的。==

根据不同的限流位置，限流可以划分为网关层限流、接入层限流、应用层限流、数据库层限流等。下面这张图，自上而下描述了服务的流量走向，非常清晰地体现出层次化的限流思路。

![image-20241112231616467](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411122316509.png)

第一层，入口网关可以针对域名或 IP 进行粗放式限流，静态资源直接走 CDN，同时在这一层还可以将一些不合法的请求拦截掉，仅放过合法请求。（WAF）

第二层，硬负载和接入层都可以实施负载均衡和限流措施，分担服务压力。它的粒度比入口网关层更细，但还没有办法对单个服务实例进行限流。

第三层，到了应用服务层，每个服务可以有自己的单机或集群限流，调用第三方服务时，也可以单独进行限流。

第四层，与数据库的交互，采用读写分离的方式，分流数据库压力，同时也可以针对数据库读写请求进行限流。

总之，在制定每一层的限流策略时，都应该抱着不信任上层限流的思维，这样即便某一层限流机制发生问题，也不至于引发全局问题，最终形成的限流体系才是最健壮、最可靠的。

**降级的实践要点**

降级是从系统功能角度出发，人为或自动地将某些不重要的功能停掉或者简化，以降低服务负载，这部分释放的资源可以去支撑更核心的功能。简而言之，弃卒保帅。

> 降级策略

降级在互联网行业的应用非常广泛，比如某大型电商在双 11 当天会将退货的功能降级，以确保核心交易链路的容量充足；某生鲜公司在遇到流量高峰期时，会将一部分个性化推荐的功能降级，以确保导购链路的工作正常，等等。抽象总结可以有以下几类策略：

![image-20241122223853657](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411222238767.png)

降级的技术实现本质上并不难，可以将开关收口至配置中心作集中式管理。那如果你已经有了一套降级系统，==该如何管理上面众多的降级开关==，把它们真正有效地推行下去，在服务容量发生风险时，及时止损，或提前止损。

> 第一，区分自动降级和人工降级

首先，降级需要平衡好自动触发和人工执行两种做法。比如在系统偶发抖动的情况下，到底是降还是不降，需要根据当时的业务情况做综合判断，这时候还是人工介入更靠谱。

自动降级比较适合触发条件明确可控的场景，比如请求调用失败次数大于一定的阈值，或是服务接口超时等情况；我将这些要点总结为下面这张导图，供你参考。

![image-20241122225027494](https://technotes.oss-cn-shenzhen.aliyuncs.com/2024/202411222250536.png)

> 第二，降级需要进行分级

因为降级操作都是有损的，所以如果进行“温柔的”降级已经能够释放足够的容量，就没有必要过度降级。

基于这个理念，我们可以根据对业务的影响程度，制定降级的分级策略。比如在导购链路上，针对个性化推荐和滚动热词功能的降级就属于不太影响用户使用的范畴，可以定为 1 级降级；而不展示商品图片和评价内容这类降级，明显会对用户使用造成不便，应定为 2 级降级。在真实发生容量问题时，可以先执行 1 级降级，如果服务恢复，则无需执行 2 级降级。

> 第三，降级需要演练

降级需要演练，而且是频繁的演练。有些服务的降级逻辑由来已久，随着服务代码的迭代更新，这些降级逻辑可能已经失效了，一旦服务出现问题真要降级时，这可是要命的。通过高频演练可以及时暴露这些无效的降级开关，防患于未然。

总结一下，降级与限流有明显的区别，前者依靠牺牲一部分功能或体验保住容量，而后者则是依靠牺牲一部分流量来保住容量。 

# ==进阶篇==

# 05 | 全链路压测：系统整体容量保障的“核武器”（上）

# 06 | 全链路压测：系统整体容量保障的“核武器”（下）

# 07 | 工具进化：如何实现一个分布式压测平台

# 08 | 容量预测（上）：第三只眼，通过AI预测服务容量瓶颈

# 09 | 容量预测（下）：为不同服务“画像”，提升容量预测准确性

# 10 | 浅谈排队论：数学之美，通过建模计算容量

# 11 | 与时俱进：云原生下的容量保障新趋势

# ==案例篇==

# 12 | 大促容量保障体系建设：怎样做好大促活动的容量保障工作（上）

# 13 | 大促容量保障体系建设：怎样做好大促活动的容量保障工作（下）

# 14 | 容量保障组织建设：容量保障需要什么样的团队？

# 15 | 小公司也能做好容量保障：建设经济实用型的容量保障体系

# 结束语 | 做时间的朋友，成功是持续累积而成的









