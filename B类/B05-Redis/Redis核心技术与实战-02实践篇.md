> 来源极客时间《Redis核心技术与实战》--蒋德钧

实践篇会介绍节省内存开销以及保存和统计海量数据的数据类型及其底层数据结构，还会围绕典型的应用场景（例如地址位置查询、时间序列数据库读写和消息队列存取），分享使用 Redis 的数据类型和 module 扩展功能来满足需求的具体方案。

# 11 | “万金油”的String，为什么不好用了？

先分享一个我曾经遇到的需求。当时，我们要开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID。

```
photo_id: 1101000051
photo_obj_id: 3301000051
```

可以看到，图片 ID 和图片存储对象 ID 正好一一对应，是典型的“键 - 单值”模式。这和 String 类型提供的“一个键对应一个值的数据”的保存形式刚好契合。

> 而且，String 类型可以保存二进制字节流，就像“万金油”一样，只要把数据转成二进制字节数组，就可以保存了。

所以，我们的第一个方案就是用 String 保存数据。我们保存了 1 亿张图片，大约用了 6.4GB 的内存。但是，随着图片数据量的不断增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB 而响应变慢的问题。

**为什么 String 类型内存开销大？**

在刚才的案例中，我们保存了 1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和图片存储对象 ID 的记录平均用了 64 字节。

> 6.4 * 1024 * 1024 * 1024 / 100000000 = 68.7 byte

但问题是，一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。图片 ID 和图片存储对象 ID 都是 10 位数，我们可以用两个 8 字节的 Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数值，所以肯定可以表示 10 位数。但是，为什么 String 类型却用了 64 字节呢？

> String 类型的底层实现。
>
> 字符串类型的值实际可以是字符串、数字、甚至是二进制，但是值最大不能超过 512 MB。
>
> ![image-20221230160040617](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/image-20221230160040617.png)
>
> 

其实，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210202129596.png" alt="image-20221020212931551" style="zoom: 50%;" />

> 这个图的 B 改成 byte。

- buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。(最大能保存多大的数据呢？)
- len：占 4 个字节，表示 buf 的已用长度。（为什么占 4 个字节，而不是 8 个或其他个？）
- alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。

另外，对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销。因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。

一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址，可以看一下下面的示意图。

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210202130142.png" alt="image-20221020213054096" style="zoom: 50%;" />

为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。

一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了（为什么？），节省了指针的空间开销。另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。

当然，当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。

为了帮助你理解 int、embstr 和 raw 这三种编码模式，我画了一张示意图，如下所示：

![image-20221020213156715](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210202131760.png)

> ![image-20230103160643703](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/image-20230103160643703.png)

好了，知道了 RedisObject 所包含的额外元数据开销，现在，我们就可以计算 String 类型的内存使用量了。

因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但是，另外的 32 字节去哪儿了呢？

> 每个 ID 使用 16 字节？难道 key 也是 RedisObject 类型的吗？

Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图所示：

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210202133557.png" alt="image-20221020213301517" style="zoom: 50%;" />

但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。

jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。

**用什么数据结构可以节省内存？**

Redis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。

压缩列表表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。

![image-20221020213433269](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210202134308.png)

压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。

- prev_len，表示前一个 entry 的长度。

  > prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。

- len：表示自身长度，4 字节；

- encoding：表示编码方式，1 字节；

- content：保存实际数据。

这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。

我们以保存图片存储对象 ID 为例，来分析一下压缩列表是如何节省内存空间的。

每个 entry 保存一个图片存储对象 ID（8 字节），此时，每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。这样一来，一个图片的存储对象 ID 所占用的内存大小是 14 字节（1+4+1+8=14），实际分配 16 字节。

这个方案听起来很好，但还存在一个问题：在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？

**如何用集合类型保存单值的键值对？**

在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。

以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。

```shell
127.0.0.1:6379> info memory
# Memory
used_memory:1039120
127.0.0.1:6379> hset 1101000 060 3302000080
(integer) 1
127.0.0.1:6379> info memory
# Memory
used_memory:1039136
```

用 info 命令查看内存开销，发现增加一条记录后，内存占用只增加了 16 字节。

不过，你可能也会有疑惑：“二级编码一定要把图片 ID 的前 7 位作为 Hash 类型的键，把最后 3 位作为 Hash 类型值中的 key 吗？”

答案是肯定的。

Redis Hash 类型的两种底层实现结构，分别是压缩列表和哈希表。Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。

如果我们往 Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries（默认512个），或者写入的单个元素大小超过了 hash-max-ziplist-value（默认64
字节），Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。

为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。

# 12 | 有一亿个keys要统计，应该用哪种集合？

> 标题：Redis 如何满足我的统计需求？
>
> 今天我打算向你介绍一下 Redis 的数据类型。说到数据类型啊，你肯定耳熟能详，说出 String, Hash, List, Set, Zset。这种思路比较常规，可以概括为：Redis 有什么，我就学什么。我不打算以这种思路讲述，这往往会使我们的学习状态变得很被动，也缺乏学习的乐趣。
>
> 我想向你讲述的思路可以概括为：我遇到了什么场景，Redis 如何满足我的使用要求。

在 Web 和移动应用的业务场景中，我们经常需要保存这样一种信息：一个 key 对应了一个数据集合。例如，手机 App 中的每天的用户登录信息：一天对应一系列用户 ID 或移动设备 ID。

我们知道，Redis 集合类型的特点就是一个键对应一系列的数据，所以非常适合用来存取这些数据。但是，在这些场景中，除了记录信息，我们往往还需要对集合中的数据进行统计，例如：在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；

通常情况下，我们面临的用户数量以及访问量都是巨大的，比如百万、千万级别的用户数量，或者千万级别、甚至亿级别的访问信息。所以，我们必须要选择能够非常高效地统计大量数据（例如亿级）的集合类型。

要想选择合适的集合，我们就得了解常用的集合统计模式。集合类型常见的统计模式有四种，包括聚合统计、排序统计、二值状态统计和基数统计。

接下来，我会和你聊聊在这些统计模式下，什么集合类型能够更快速地完成统计，而且还节省内存空间。

**聚合统计**

所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。

假设我们现在要统计手机 App 每天的新增用户数和第二天的留存用户数。

我们把每一天登录的用户 ID，记录到一个新集合中，我们把这个集合叫作每日用户 Set。key 是`user:id`以及当天日期，例如 `user:id:20200803`；value 是 Set 集合，记录当天登录的用户 ID。

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210252219410.png" alt="image-20221025221924367" style="zoom:50%;" />

在统计每天的新增用户时，我们只用计算每日用户 Set 和累计用户 Set 的差集就行。

我借助一个具体的例子来解释一下。

假设我们的手机 App 在 2020 年 8 月 3 日上线，那么，8 月 3 日前是没有用户的。此时，累计用户 Set 是空集，当天登录的用户 ID 会被记录到 key 为`user:id:20200803`的 Set 中。所以，`user:id:20200803`这个 Set 中的用户就是当天的新增用户。

要统计每日新增用户数，需要分两步进行。首先，我们计算累计用户 Set 和`user:id:20200803`Set 的并集结果，结果保存在`user:id`这个累计用户 Set 中，如下所示：

> ```
> 用法：SUNIONSTORE destination key1 [key2]
> 所有给定集合的并集存储在 destination 集合中
> ```

```shell
SUNIONSTORE user:id user:id user:id:20200803
```

此时，`user:id` 这个累计用户 Set 中就有了 8 月 3 日的用户 ID。

接着，等到 8 月 4 日再统计时，我们把 8 月 4 日登录的用户 ID 记录到`user:id:20200804`的 Set 中。接下来，我们执行 SDIFFSTORE 命令计算累计用户 Set 和`user:id:20200804` Set 的差集，结果保存在 key 为`user:new`的 Set 中，如下所示：

> ```
> 用法：SDIFFSTORE destination key1 [key2]
> 返回给定所有集合的差集并存储在 destination 中
> ```

```shell
SDIFFSTORE user:new user:id:20200804 user:id
```

这个差集中的用户 ID 在 `user:id:20200804` 的 Set 中存在，但是不在累计用户Set 中。所以，`user:new` 这个 Set 中记录的就是 8 月 4 日的新增用户。

当要计算 8 月 4 日的留存用户时，我们只需要再计算 `user:id:20200803` 和 `user:id:20200804` 两个 Set 的交集，就可以得到同时在这两个集合中的用户 ID 了，这些就是在 8 月 3 日登录，并且在 8 月 4 日留存的用户。执行的命令如下：

> ```
> 用法：SINTERSTORE destination key1 [key2]
> 返回给定所有集合的交集并存储在 destination 中
> ```

```shell
SINTERSTORE user:id:rem user:id:20200803 user:id:20200804
```

当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。不过，我要提醒你一下，这里有一个潜在的风险。

Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。

**排序统计**

接下来，我们再来聊一聊应对集合元素排序需求的方法。我以在电商网站上提供最新评论列表的场景为例。

最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。在 Redis 常用的 4 个集合类型中（List、Hash、Set、Sorted Set），List 和 Sorted Set 就属于有序集合。List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。

我先说说用 List 的情况。每个商品对应一个 List，这个 List 包含了对这个商品的所有评论，而且会按照评论时间保存这些评论，每来一个新评论，就用 LPUSH 命令把它插入 List 的队头。

在只有一页评论的时候，我们可以很清晰地看到最新的评论，但是，在实际应用中，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，List 就可能会出现问题了。

假设当前的评论 List 是{A, B, C, D, E, F}（其中，A 是最新的评论，以此类推，F 是最早的评论），在展示第一页的 3 个评论时，我们可以用下面的命令，得到最新的三条评论 A、B、C：

> ```
> 用法：LRANGE key start stop
> 获取列表指定范围内的元素
> ```

```shell
LRANGE product1 0 2
1) "A"
2) "B"
3) "C"
```

但是，如果在展示第二页前，又产生了一个新评论 G，评论 G 就会被 LPUSH 命令插入到评论 List 的队头，评论 List 就变成了{G, A, B, C, D, E, F}。此时，再用刚才的命令获取第二页评论时，就会发现，评论 C 又被展示出来了，也就是 C、D、E。

之所以会这样，关键原因就在于，List 是通过元素在 List 中的位置来排序的，当有一个新元素插入时，原先的元素在 List 中的位置都后移了一位。所以，对比新元素插入前后，List 相同位置上的元素就会发生变化，用 LRANGE 读取时，就会读到旧元素。

和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。

我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set 中。Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。

> ```
> 用法：ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT]
> 通过分数返回有序集合指定区间内的成员
> ```

假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的 10 条评论：

> 应该是越新评论权重越小吧？作者的 Redis 版本是多少？我的是 6.2.5，分数越小越靠前。

```shell
ZRANGEBYSCORE comments N-9 N
```

> 权重可以是负数吗？答案是可以的，排序的分数是从小到大的。
>
> ```
> 10.118.32.170:0>zadd product001:comments -10 A -9 B
> "2"
> 
> 10.118.32.170:0>zrangebyscore product001:comments -10 0
>  1)  "A"
>  2)  "B"
> ```

所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 Sorted Set。

**二值状态统计**

我们再来分析下第三个场景：统计用户在手机 App 上的签到打卡信息；在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。

我来解释一下它的实现原理。

Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。你可以把 Bitmap 看作是一个 bit 数组。

那么，具体该怎么用 Bitmap 进行签到统计呢？

假设我们要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，就可以按照下面的步骤进行操作。

第一步，执行下面的命令，记录该用户 8 月 3 号已签到（bit 位设置为 1）。

```shell
SETBIT uid:sign:3000:202008 2 1
```

第二步，检查该用户 8 月 3 日是否签到。

```shell
GETBIT uid:sign:3000:202008 2
```

第三步，统计该用户在 8 月份的签到次数（bit 数组中所有“1”的个数）。

```shell
BITCOUNT uid:sign:3000:202008
```

这样，我们就知道该用户在 8 月份的签到情况了。如果记录了 1 亿个用户 10 天的签到情况，你有办法统计出这 10 天连续签到的用户总数吗？

Bitmap 支持用 BITOP 命令对多个 Bitmap 按位做“与”“或”“异或”的操作，操作的结果会保存到一个新的 Bitmap 中。

我以按位“与”操作为例来具体解释一下。从下图中，可以看到，三个 Bitmap bm1、bm2 和 bm3，对应 bit 位做“与”操作，结果保存到了一个新的 Bitmap 中（示例中，这个结果 Bitmap 的 key 被设为“resmap”）。

![image-20221026220442609](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210262204757.png)

回到刚刚的问题，在统计 1 亿个用户连续 10 天的签到情况时，你可以把每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit 对应一个用户当天的签到情况。

接下来，我们对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。在这个 Bitmap 中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。最后，我们可以用 BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了。

现在，我们可以计算一下记录了 10 天签到情况后的内存开销。每天使用 1 个 1 亿位的 Bitmap，大约占 12MB 的内存（10^8/8/1024/1024），10 天的 Bitmap 的内存开销约为 120MB，内存压力不算太大。不过，在实际应用时，最好对 Bitmap 设置过期时间，让 Redis 自动删除不再需要的签到记录，以节省内存开销。

所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效地节省内存空间。

**基数统计**

最后，我们再来看一个统计场景：基数统计。基数统计就是指统计一个集合中不重复的元素个数。对应到我们刚才介绍的场景中，就是统计网页的 UV。

网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用 Set 类型。

我们来结合一个例子看一看用 Set 的情况。

有一个用户 user1 访问 page1 时，你把这个信息加到 Set 中：

```
SADD page1:uv user1
```

当你需要统计 UV 时，可以直接用 SCARD 命令，这个命令会返回一个集合中的元素个数。

但是，如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。

当然，你也可以用 Hash 类型记录 UV。

例如，你可以把用户 ID 作为 Hash 集合的 key，当用户访问页面时，就用 HSET 命令（用于设置 Hash 集合元素的值），对这个用户 ID 记录一个值“1”，表示一个独立访客，用户 1 访问 page1 后，我们就记录为 1 个独立访客，如下所示：

```
HSET page1:uv user1 1
```

即使用户 1 多次访问页面，重复执行这个 HSET 命令，也只会把 user1 的值设置为 1，仍然只记为 1 个独立访客。当要统计 UV 时，我们可以用 HLEN 命令统计 Hash 集合中的所有元素个数。

> 计算一下内存用量。

但是，和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间。那么，有什么办法既能完成统计，还能节省内存吗？

这时候，就要用到 Redis 提供的 HyperLogLog 了。

HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。

在 Redis 中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。

在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。

> ```
> 用法：PFADD key element [element ...]
> 添加指定元素到 HyperLogLog 中。
> ```

```
PFADD page1:uv user1 user2 user3 user4 user5
```

接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。

```
PFCOUNT page1:uv
```

> 关于 HyperLogLog 的具体实现原理，可以查看：https://zhuanlan.zhihu.com/p/58519480

不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。

# 13 | GEO是什么？还可以定义新的数据类型吗？

我们先来了解下扩展数据类型 GEO 的实现原理和使用方法。

在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中，我们来看一下它的底层结构。

**GEO 的底层结构**

一般来说，在设计一个数据类型的底层结构时，我们首先需要知道，要处理的数据有什么访问特点。所以，我们需要先搞清楚位置信息到底是怎么被存取的。

我以叫车服务为例，来分析下 LBS 应用中经纬度的存取特点。

1. 每一辆网约车都有一个编号（例如 33），网约车需要将自己的经度信息（例如 116.034579）和纬度信息（例如 39.000452 ）发给叫车应用。
2. 用户在叫车的时候，叫车应用会根据用户的经纬度位置（例如经度 116.054579，纬度 39.030452），查找用户的附近车辆，并进行匹配。
3. 等把位置相近的用户和车辆匹配上以后，叫车应用就会根据车辆的编号，获取车辆的信息，并返回给用户。

可以看到，一辆车（或一个用户）对应一组经纬度，并且随着车（或用户）的位置移动，相应的经纬度也会变化。这种数据记录模式属于一个 key（例如车 ID）对应一个 value（一组经纬度）。我们可以把不同车辆的 ID 和它们对应的经纬度信息存在 Hash 集合中，如下图所示：

![image-20221027221033798](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210272210871.png)

同时，Hash 类型的 HSET 操作命令，会根据 key 来设置相应的 value 值，所以，我们可以用它来快速地更新车辆变化的经纬度信息。

到这里，Hash 类型看起来是一个不错的选择。但问题是，对于一个 LBS 应用来说，除了记录经纬度信息，还需要根据用户的经纬度信息在车辆的 Hash 集合中进行范围查询。一旦涉及到范围查询，就意味着集合中的元素需要有序，但 Hash 类型的元素是无序的，显然不能满足我们的要求。

我们再来看看使用 Sorted Set 类型是不是合适。

Sorted Set 类型也支持一个 key 对应一个 value 的记录模式，其中，key 就是 Sorted Set 中的元素，而 value 则是元素的权重分数。更重要的是，Sorted Set 可以根据元素的权重分数排序，支持范围查询。这就能满足 LBS 服务中查找相邻位置的需求了。

![image-20221027221140417](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202210272211488.png)

这时问题来了，Sorted Set 元素的权重分数是一个浮点数（float 类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的，那具体该怎么进行保存呢？

这就要用到 GEO 类型中的 GeoHash 编码了。

**GeoHash 的编码方法**

为了能高效地对经纬度进行比较，Redis 采用了业界广泛使用的 GeoHash 编码方法，这个方法的基本原理就是“二分区间，区间编码”。

举个例子，假设我们要编码的经度值是 116.37，我们用 5 位编码值，做 5 次分区。

我们先做第一次二分区操作，把经度区间[-180,180]分成了左分区[-180,0) 和右分区[0,180]，此时，经度值 116.37 是属于右分区[0,180]，所以，我们用 1 表示第一次二分区后的编码值。

接下来，我们做第二次二分区：把经度值 116.37 所属的[0,180]区间，分成[0,90) 和[90,180]。此时，经度值 116.37 还是属于右分区[90,180]，所以，第二次分区后的编码值仍然为 1。

第三次对[90,180]进行二分区，经度值 116.37 落在了分区后的左分区[90, 135)中，所以，第三次分区后的编码值就是 0。

按照这种方法，做完 5 次分区后，我们把经度值 116.37 定位在[112.5, 123.75]这个区间，并且得到了经度值的 5 位编码值，即 11010。这个编码过程如下表所示：

![image-20230104153501913](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/image-20230104153501913.png)

对纬度的编码方式，和对经度的一样，下面这张表显示了对纬度值 39.86 的编码过程。

![image-20230104153512297](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/image-20230104153512297.png)

> 经度范围：[-180,180]<br/>
> 纬度范围：[-90，90]

当一组经纬度值都编完码后，我们再把它们的各自编码值组合在一起，组合的规则是：最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从 0 开始算，奇数位从 1 开始算。

我们刚刚计算的经纬度（116.37，39.86）的各自编码值是 11010 和 10111，组合之后，第 0 位是经度的第 0 位 1，第 1 位是纬度的第 0 位 1，第 2 位是经度的第 1 位 1，第 3 位是纬度的第 1 位 0，以此类推，就能得到最终编码值 1110011101，如下图所示：

![image-20221101213420780](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202211012134858.png)

用了 GeoHash 编码后，原来无法用一个权重分数表示的一组经纬度（116.37，39.86）就可以用 1110011101 这一个值来表示，就可以保存为 Sorted Set 的权重分数了。

**如何操作 GEO 类型？**

在使用 GEO 类型时，我们经常会用到两个命令，分别是 GEOADD 和 GEORADIUS。

- GEOADD 命令：用于把一组经纬度信息和相对应的位置名称记录到 GEO 类型集合中；

  ```
  用法：GEOADD key longitude latitude member [longitude latitude member ...]
  ```

- GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围。

  ```
  用法：GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
  ```

我还是以叫车应用的车辆匹配场景为例，介绍下具体如何使用这两个命令。

假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：

```
GEOADD cars:locations 116.034579 39.030452 33
```

当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。

另外，我们还可以进一步限定返回的车辆信息。比如，我们可以使用 ASC 选项，让返回的车辆信息按照距离这个中心位置从近到远的方式来排序，以方便选择最近的车辆；还可以使用 COUNT 选项，指定返回的车辆信息的数量。

```
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

可以看到，使用 GEO 数据类型可以非常轻松地操作经纬度这种信息。

> 参考资料：
>
> - 菜鸟教程：https://www.runoob.com/redis/redis-tutorial.html

# 14 | 如何在Redis中保存时间序列数据？

> 本篇有点偏，不想了解

# 15 | 消息队列的考验：Redis有哪些解决方案？

> Redis 不是专业的消息队列，这块可以看专业的消息队列。

# 16 | 异步机制：如何避免单线程模型的阻塞？

从这节课开始，我会用 6 节课的时间介绍影响 Redis 性能的 5 大方面的潜在因素，分别是：

Redis 内部的阻塞式操作；

CPU 核和 NUMA 架构的影响；

**Redis 实例有哪些阻塞点？**

![image-20230103215557910](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301032155034.png)

1. 和客户端交互时的阻塞点

2. 和磁盘交互时的阻塞点

3. 主从节点交互时的阻塞点

4. 切片集群实例交互时的阻塞点

我们来总结下刚刚找到的五个阻塞点：

- 集合全量查询和聚合操作；
- bigkey 删除；
- 清空数据库；
- AOF 日志同步写；
- 从库加载 RDB 文件。

不过，这个时候，问题来了：这五大阻塞式操作都可以被异步执行吗？

**哪些阻塞点可以异步执行？**





**异步的子线程机制**

![image-20230103220428347](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301032204412.png)

# 17 | 为什么CPU结构也会影响Redis的性能？

今天，我们就来学习下目前主流服务器的 CPU 架构，以及基于 CPU 多核架构和多 CPU 架构优化 Redis 性能的方法。

**主流的 CPU 架构**



![image-20230104204703191](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042047306.png)

为了方便你理解，我用一张图展示一下物理核和逻辑核，以及一级、二级缓存的关系。

![image-20230104204900598](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042049664.png)

下图显示的就是多 CPU Socket 的架构，图中有两个 Socket，每个 Socket 有两个物理核。

![image-20230104204942214](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042049287.png)

**CPU 多核对 Redis 性能的影响**

context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。

**CPU 的 NUMA 架构对 Redis 性能的影响**

如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。

![image-20230104205743039](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042057109.png)

所以，你一定要注意 NUMA 架构下 CPU 核的编号方法，这样才不会绑错核。

**绑核的风险和解决方案**

当我们把 Redis 实例绑到一个 CPU 逻辑核上时，就会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致 Redis 请求延迟增加。

针对这种情况，我来给你介绍两种解决方案，分别是一个 Redis 实例对应绑一个物理核和优化 Redis 源码。

方案一：一个 Redis 实例对应绑一个物理核

方案二：优化 Redis 源码

使用源码优化方案，我们既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。相比使用 taskset 绑核来说，这个方案可以进一步降低绑核的风险。

希望你能掌握绑核优化方案，并把它应用到实践中。

# 18 | 波动的响应延迟：如何应对变慢的Redis？（上）

举个小例子，在秒杀场景下，一旦 Redis 变慢了，大量的用户下单请求就会被拖慢，也就是说，用户提交了下单申请，却没有收到任何响应，这会给用户带来非常糟糕的使用体验，甚至可能会导致用户流失。

很明显，Redis 变慢会带来严重的连锁反应。

![image-20230104211105105](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042111177.png)

接下来的两节课，我再向你介绍一下如何系统性地应对 Redis 变慢这个问题。

**Redis 真的变慢了吗？**

当你发现 Redis 命令的执行时间突然就增长到了几秒，基本就可以认定 Redis 变慢了。

**如何应对 Redis 变慢？**

![image-20230104211741013](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042117086.png)

**Redis 自身操作特性的影响**

1. 慢查询命令

Redis 官方文档中对每个命令的复杂度都有介绍，当你需要了解某个命令的复杂度时，可以直接查询。

2. 过期 key 操作

其中一个重要来源，就是频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key，这就会导致，在同一秒内有大量的 key 同时过期。

# 19 | 波动的响应延迟：如何应对变慢的Redis？（下）

但是，如果在排查时，你发现 Redis 没有执行大量的慢查询命令，也没有同时删除大量过期 keys，那么，我们是不是就束手无策了呢？

如果上节课的方法不管用，那就说明，你要关注影响性能的其他机制了，也就是文件系统和操作系统。

那么，接下来，我再从这两个层面，继续给你介绍，如何进一步解决 Redis 变慢的问题。

![image-20230104212456032](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042124103.png)

**文件系统：AOF 模式**

![image-20230104212747366](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042127440.png)

```
no-appendfsync-on-rewrite yes
```

**操作系统：swap**

接下来，我就再说一个潜在的瓶颈：操作系统的内存 swap。

**操作系统：内存大页**

首先，我们要先排查下内存大页。方法是：在 Redis 实例运行的机器上执行如下命令:

```
cat /sys/kernel/mm/transparent_hugepage/enabled
```

如果执行结果是 always，就表明内存大页机制被启动了；如果是 never，就表示，内存大页机制被禁止。

在实际生产环境中部署时，我建议你不要使用内存大页机制，操作也很简单，只需要执行下面的命令就可以了：

```
echo never /sys/kernel/mm/transparent_hugepage/enabled
```

**小结**

应对 Redis 变慢的方法。为了方便你应用，我给你梳理了一个包含 9 个检查点的 Checklist，希望你在遇到 Redis 性能变慢时，按照这些步骤逐一检查，高效地解决问题。

1. 获取 Redis 实例在当前环境下的基线性能。
1. 是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算
命令放在客户端做。
1. 是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期
时间上加一个随机数，避免同时删除。
1. 是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，
可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用
SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客
户端完成。
5. Redis AOF 配置级别是什么？
6. Redis 实例的内存使用是否过大？
7. 在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。
8. 是否运行了 Redis 主从集群？
9. 是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？

# 20 | 删除数据后，为什么内存占用率还是很高？

在使用 Redis 时，我们经常会遇到这样一个问题：明明做了数据删除，数据量已经不大了，为什么使用 top 命令查看时，还会发现 Redis 占用了很多内存呢？

这节课，我就和你聊聊 Redis 的内存空间存储效率问题，探索一下，为什么数据已经删除了，但内存却闲置着没有用，以及相应的解决方案。

**什么是内存碎片？**

![image-20230104214235213](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042142294.png)

**内存碎片是如何形成的？**

内因：内存分配器的分配策略

Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc。

外因：键值对大小不一样和删改操作

**如何判断是否有内存碎片？**



**如何清理内存碎片？**

![image-20230104215030892](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301042150976.png)

# 21 | 缓冲区：一个可能引发“惨案”的地方

毫不夸张地说，缓冲区是用来避免请求或数据丢失的惨案的，但也只有用对了，才能真正起到“避免”的作用。

**客户端输入和输出缓冲区**

![image-20230106223443087](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301062234229.png)

**如何应对输入缓冲区溢出？**

**如何应对输出缓冲区溢出？**

MONITOR 的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出。所以，我要给你一个小建议：MONITOR 命令主要用在调试环境中，不要在线上生产环境中持续使用 MONITOR。当然，如果在线上环境中偶尔使用 MONITOR 检查 Redis 的命令执行情况，是没问题的。

**主从集群中的缓冲区**

**复制缓冲区的溢出问题**

# 22 | 第11～21讲课后思考题答案及常见问题答疑

**第11讲**

问题：除了 String 类型和 Hash 类型，还有什么类型适合保存第 11 讲中所说的图片吗？

答案：除了 String 和 Hash，我们还可以使用 Sorted Set 类型进行保存。Sorted Set 的元素有 member 值和 score 值，可以像 Hash 那样，使用二级编码进行保存。具体做法是，把图片 ID 的前 7 位作为 Sorted Set 的 key，把图片 ID 的后 3 位作为 member 值，图片存储对象 ID 作为 score 值。

Sorted Set 中元素较少时，Redis 会使用压缩列表进行存储，可以节省内存空间。不过，和 Hash 不一样，Sorted Set 插入数据时，需要按 score 值的大小排序。当底层结构是压缩列表时，Sorted Set 的插入性能就比不上 Hash。所以，在我们这节课描述的场景中，Sorted Set 类型虽然可以用来保存，但并不是最优选项。

**第13讲**

问题：你在日常的实践过程中，还用过 Redis 的其他数据类型吗？

答案：除了我们课程上介绍的 5 大基本数据类型，以及 HyperLogLog、Bitmap、GEO，Redis 还有一种数据类型，叫作布隆过滤器。它的查询效率很高，经常会用在缓存场景中，可以用来判断数据是否存在缓存中。我会在后面（第 25 讲）具体地介绍一下它。

# 23 | 旁路缓存：Redis是如何工作的？

如果 Redis 做缓存时出现了问题，比如说缓存失效，那么，大量请求就会直接积压到数据库层，必然会给数据库带来巨大的压力，很可能会导致数据库宕机或是故障，那么，业务应用就没有办法存取数据、响应用户请求了。这种生产事故，肯定不是我们希望看到的。

正因为 Redis 用作缓存的普遍性以及它在业务应用中的重要作用，所以，我们需要系统地掌握缓存的一系列内容，包括工作原理、替换策略、异常处理和扩展机制。具体来说，我们需要解决四个关键问题：

- Redis 缓存具体是怎么工作的？
- Redis 缓存如果满了，该怎么办？
- 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
- Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？

**缓存的特征**

![image-20230106225342897](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301062253984.png)

![image-20230106225423690](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301062254775.png)

**Redis 缓存处理请求的两种情况**

- 缓存命中：Redis 中有相应数据，就直接读取 Redis，性能非常快。
- 缓存缺失：Redis 中没有保存相应数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失，为了让后续请求能从缓存中读取到数据，我们需要把缺失的数据写入 Redis，这个过程叫作缓存更新。缓存更新操作会涉及到保证缓存和数据库之间的数据一致性问题，关于这一点，我会在第 25 讲中再具体介绍。

![image-20230106225555281](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301062255366.png)

**Redis 作为旁路缓存的使用操作**



**缓存的类型**

- 只读缓存
- 读写缓存



# 24 | 替换策略：缓存满了怎么办？

**设置多大的缓存容量合适？**



**Redis 缓存有哪些淘汰策略？**

![image-20230106225840486](https://technotes.oss-cn-shenzhen.aliyuncs.com/2022/202301062258577.png)

**如何处理被淘汰的数据？**



# 25 | 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？

**缓存和数据库的数据不一致是如何发生的？**



**如何解决数据不一致问题？**



# 26 | 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？





# 27 | 缓存被污染了，该怎么办？



# 33 | 脑裂：一次奇怪的数据丢失









