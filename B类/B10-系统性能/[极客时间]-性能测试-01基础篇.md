> 来自极客时间《性能测试实战30讲》--高楼

# 开篇词

在这个课程中，“性能测试”不仅仅包括测试，还包括分析和调优。

第一个模块：性能测试基础篇。

第二个模块：性能测试工具的实操。

第三个模块：性能分析。

第四个模块：性能测试分析过程。

# 01丨性能综述：性能测试的概念

**性能测试要有指标**

时间指标、容量指标、资源利用率指标。

**性能测试要有模型**

业务模型，比如说，我们有 100 种业务，只有 50 个业务需要有并发量，那就要把这些有并发的业务统计出来，哪个业务并发多，哪个业务并发少，做压力测试时就要控制好这样的比例。

监控模型，这个部分的监控，要有分层、分段的能力，要有全局监控、定向监控的能力。

**性能测试要有方案**

方案规定的内容中有几个关键点，分别是测试环境、测试数据、测试模型、性能指标、压力策略、准入准出和进度风险。

**性能测试要有预定的条件**

这里的条件包括软硬件环境、测试数据、测试执行策略、压力补偿等内容。要是展开来说，在场景执行之前，这些条件应该是确定的。

**性能测试中要有场景**

1. 基准性能场景
2. 容量性能场景
3. 稳定性性能场景
4. 异常性能场景

**性能测试中要有分析调优**

性能项目分以下几类：

- 新系统性能测试类

  这样的项目一般都会要求测试出系统的最大容量。

- 旧系统新版本性能测试类

  只要性能不下降，就可以根据历史数据推算容量。

- 新系统性能测试优化类

  这类系统不仅要测试出最大容量，还要求调优到最好。

对性能团队的职责定位有如下几种：

1. 性能验证
2. 性能测试
3. 性能测试 + 分析调优

**性能测试要有结果报告**

在报告中写上 TPS、响应时间以及资源对比图。

**性能测试概念总结**

![image-20210528225408650](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210528225408.png)

# 02丨性能综述：TPS和响应时间之间是什么关系？

**系统性能描述图**

关于系统性能，有下面这样一张描述图：

![image-20210529213130760](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210529213130.png)

图中定义了三条曲线、三个区域、两个点以及三个状态描述。

三条曲线：使用率（U）、吞吐量曲线（X）、响应时间曲线（R）。

三个区域：轻负载区（Light Load）、重负载区（Heavy Load）、塌陷区（Buckle Zone）。

两个点：最优并发用户数（The Optimum Number of Consurrent Users）、最大并发用户数（The Maximum Number of Consurrent Users）。

三个状态描述：资源饱和（Resource Saturated）、吞吐下降（Throughput Falling）、用户受影响（End Users Effected）。

**TPS和响应时间**

![image-20210529215017916](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210529215017.png)

上图中蓝线表示 TPS，黄线表示响应时间。

在 TPS 增加的过程中，响应时间一开始会处在较低的状态，也就是在 A 点之前。

接着响应时间开始有些增加，直到业务可以承受的时间点 B，这时 TPS 仍然有增长的空间。

再接着增加压力，达到 C 点时，达到最大 TPS。我们再接着增加压力，响应时间接着增加，但 TPS 会有所下降。

> 这里并不是必然的，有些系统在队列上处理得很好，会保持稳定的 TPS，然后多出来的请求都被友好拒绝。

最后，D 点之后响应时间过长，达到了超时的程度。

在实际的性能测试中，基准性能场景也好，容量性能场景也好，都是需要递增的，而不是上来就用几百几千的线程。同时，递增也是要连续的，而不是 100 线程、200 线程、300 线程这样断开执行场景。

> 性能场景为什么要连续？而不是断开？
>
> 递增线程数可以记录每次的性能指标，画曲线对比分析，来观察指标变化的趋势，找出性能瓶颈以及服务器最大处理能力。

# 03丨性能指标：怎么理解TPS、QPS、RT、吞吐量这些性能指标？

性能测试行业常用的性能指标表示法。

| 简写       | 英文全称                           | 含义                                                         |
| ---------- | ---------------------------------- | ------------------------------------------------------------ |
| RT         | Response Time                      | 响应时间。通常我们说的响应时间，都是包括了Request Time和Response Time。 |
| HPS        | Hits Per Second                    | 每秒点击数                                                   |
| TPS        | Transactions Per Second            | 每秒事务数                                                   |
| QPS        | Queries Per Second                 | 在MySQL中指每秒SQL数                                         |
| RPS        | Requests Per Second                | 每秒请求数                                                   |
| CPS        | Codes Per Second                   | 在HTTP协议中，CPS偶有提及，指的是HTTP返回码每秒。            |
| PV         | Page View                          | 页面浏览量                                                   |
| UV         | Unique Visitor                     | 独立访问者                                                   |
| IP         | Internet Protocol                  | 本意是IP地址，在性能中一般指独立IP数                         |
| Throughput | /                                  | 吞吐量                                                       |
| IOPS       | Input/Output Operations Per Second | 通常描述磁盘                                                 |

**TPS**

TPS 是性能领域中一个关键的性能指标概念，它用来描述每秒事务数，可以反映出一个系统的处理能力。TPS 在不同的行业、不同的业务中定义的粒度也是不同的。所以不管你在哪里用 TPS，一定要有一个前提，就是所有相关的人都要知道你的 T 是如何定义的。

以下图为例：

![image-20210530215245305](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210530215245.png)

如果我们要单独测试接口 1、2、3，那 T 就是接口级的；如果我们要从用户的角度来下一 个订单，那 1、2、3 应该在一个 T 中，这就是业务级的了。

**RPS**

如果一个用户点击了一次，发出来 3 个 HTTP Request，调用了 2 次订单服务，调用了 2 次库存服务，调用了 1 次积分服务，那么这个 Request 该如何计算?

![image-20210530211539445](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210530211539.png)

如果要描述整体，最多算是有 3 个 RPS。如果从 HTTP 协议的角度去理解，那么 HTTP Request 算是一个比较准确的描述了，但它本身的定义并没有包含业务。如果赋予它业务的含义，那么用它来描述性能也是可以的。

**压力工具中的线程数（用户数）与 TPS**

“并发”这个概念是需要具体的指标来承载的。

你可以说，我的并发是 1000TPS，或者 1000RPS，或者 1000HPS。但不能说并发 1000 这样没有单位的词。

以下图为例，来描述线程数与 TPS。

![image-20210531220842593](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210531220842.png)

上图有 4 个并发线程，每个线程都可以在一秒内完成 4 个事务，所以总的 TPS 是 16。

那么用户数怎么来定义呢？一个系统如果有 1 万个用户在线，很多业务中，并发度都会低于 5%，甚至低于 1%。拿 5% 来计算，就是 
$$
10000 用户 * 5\%=500(TPS)
$$
注意这里是 TPS 而不是并发线程数。如果这时响应时间是 100ms，那显然并发线程数是
$$
500TPS / (1000ms / 100ms)=50(并发线程)
$$
通过这样简单的计算逻辑，我们就可以看出来用户数、线程数和 TPS 之间的关系了。

# 04丨JMeter和LoadRunner：要知道工具仅仅只是工具

**性能工程师学习的三个阶段**

- 性能工具学习阶段

工具只做两件事情，做脚本和发压力。

- 性能场景学习阶段

比如说压力策略，应该用一秒 Ramp up 10 个用户，还是 20 个用户，还是 100 个用户？这应该怎么判断呢?

- 性能分析学习阶段

怎么判断性能瓶颈在哪里？

**公司性能团队成长阶段**

- 性能团队初建

这时的团队，可以执行场景，可以拿出数据，但工作出的结果并不理想。

- 性能团队初成熟

到了这个阶段，团队已经可以应付版本的更迭带来的性能工作压力。

- 性能团队已成熟

能回答出以下问题：

1. 通过测试和分析优化之后，性能提升了多少?

   一个成熟的团队应该回答的是：提升了 10 倍，我们调优了什么什么。

2. 通过你的测试和分析优化之后，节省了多少成本?

   之前的版本用了 200 台机器，而通过我们的测试分析优化之后，只用到了 100 台机器。

**工具如何选择？**

工具只是一个压力发起者，工具应该如何用，完全取决于用的人，而不是工具本身。

没有一个工具可以直接告诉你瓶颈在哪里，能告诉你的只
是数据是什么。

对于企业来说，如果是一个需要支持每秒 100TPS 的企业内部业务系统，找一台 4C8G 的机器，就压得够了。如果是一个需要支持万级 TPS，可以自己搭建一套测试环境。

对个人来说呢，压测工具市场首选学习 JMeter，其次是 LoadRunner。

# 05丨指标关系：你知道并发用户数应该怎么算吗？

TPS 和并发数是什么关系呢？ 在并发中谁来承载”并发“这个概念呢？

**什么是并发？**

并发包括”绝对并发”和“相对并发”这两个概念。绝对并发指的是同一时刻的并发数；相对并发指的是一个时间段内发生的事情。

![image-20210601231818489](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210601231818.png)

上图中的系统的绝对并发用户数是 4。如果描述 1 秒内的并发用户数，那就是 16。

> “绝对并发”这个概念，不管是用来描述硬件细化的层面，还是用来描述业务逻辑的层面，都是没什么意义的。

如何来描述上面的并发用户数呢？在这里我建议用 TPS 来承载“并发”这个概念。并发数是 16TPS，就是 1 秒内整个系统处理了 16 个事务。

**在线用户数怎么计算？**

那么新问题又来了，在线用户数和并发用户数应该如何算呢？下面我们接着来看示意图：

![image-20210601232708435](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210601232708.png)

如上图所示，总共有 32 个用户进入了系统，但是绿色的用户并没有任何动作，那么显然，在线用户数是 32 个，并发用户数是 16 个，这时的并发度就是 50%。

在一个系统中，通过把在线用户数据放到 Redis 这样的缓存服务器中。所以如果想知道在线的最大的用户数是多少，直接拿缓存的内存来算就可以了。

假设一个用户进入系统之后，需要用 10k 内存来维护一个用户的信息，那么 10G 的内存就能 hold 住 1,048,576 个用户的数据，这就是最大在线用户数了。在实际的项目中，我们还会将超时放在一起来考虑。

**并发用户数怎么计算？**

要想计算并发用户和在线用户数之间的关系，就要计算出并发度。我们通过一个示意图来说明：

![image-20210601234326518](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210601234326.png)

通过这个图，我们可以看到一个简单的计算逻辑：
1. 如果有 10000 个在线用户数，同时并发度是 1%，那显然并发用户数就是 100。
2. 如果每个线程的 20TPS，显然只需要 5 个线程就够了（请注意，这里说的线程指的是压力机的线程数）。
3. 这时对 Server 来说，它处理的就是 100TPS，平均响应时间是 50ms。50ms 就是根据1000ms/20TPS 得来的（请注意，这里说的平均响应时间会在一个区间内浮动，但只要TPS 不变，这个平均响应时间就不会变）。
4. 如果我们有两个 Server 线程来处理，那么一个线程就是 50TPS，这个很直接吧。
5. 请大家注意，这里我有一个转换的细节，那就是并发用户数到压力机的并发线程数。这一步，我们通常怎么做呢？就是基准测试的第一步。关于这一点，我们在后续的场景中交待。

而我们通常说的“并发”这个词，依赖 TPS 来承载的时候，指的都是 Server 端的处理能力，并不是压力工具上的并发线程数。在上面的例子中，我们说的并发就是指服务器上 100TPS 的处理能力，而不是指 5 个压力机的并发线程数。请你切记这一点，以免沟通障碍。

# 06丨倾囊相授：我毕生所学的性能分析思路都在这里了

性能测试分析的能力阶梯视图：

![image-20211115221230834](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115221236.png)

1. 工具操作：包括压力工具、监控工具、剖析工具、调试工具。
2. 数值理解：包括上面工具中所有输出的数据。
3. 趋势分析、相关性分析、证据链分析：就是理解了工具产生的数值之后，还要把它们的逻辑关系想明白。这才是性能测试分析中最重要的一环。
4. 最后才是调优：有了第 3 步之后，调优的方案策略就有很多种了，具体选择取决于调优成本和产生的效果。

那么怎么把这些内容都融会贯通呢？主要有以下几点：

1. 瓶颈的精准判断；
2. 线程递增的策略；
3. 性能衰减的过程；
4. 响应时间的拆分；
5. 构建分析决策树；
6. 场景的比对。

下面我们就来说说性能测试分析的几个重要环节。

## 1. 瓶颈的精准判断

对性能瓶颈做出判断是性能分析的第一步，有了问题才能分析调优。

- TPS曲线

之前有很多人在描述性能测试的过程中，说要找到性能测试中曲线上的“拐点”，但大部分系统其实是没有明确的拐点的。

举例来说，TPS 的视图如下：

![1](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222513.png)

与之对应的响应时间视图如下：

![2](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222546.png)

从图中可以看出，瓶颈在第二个压力阶梯上已经出现了。因为响应时间增加了，TPS 增加得却没有那么多，到第三个阶梯时，显然增加的 TPS 更少了，响应时间也在不断地增加，所以，性能瓶颈在加剧，越往后就越明显。

所以我们的判断是：

1. 有瓶颈；
2. 瓶颈和压力有关；
3. 压力呈阶梯，并且增长幅度在衰减；

再来看下面这张 TPS 图：

![3](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222610.png)

这张图显然是判断不出来拐点的。再来看下面这张 TPS 图：

![下载](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115221755.png)

这种比较有规律的问题，显然不是压力大小的原因。为什么呢？因为 TPS 周期性地出现降低，并且最大的 TPS 也都恢复到了差不多的水位上。所以，即使是压力降低，也最多降低最大的 TPS 水位，会让问题出现得更晚一点，但是不会不出现。

综合以上，如果画一个示意图的话，TPS 的衰减过程大概会如下所示：

![4](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222746.png)

在这样的趋势图中，我们是看不到明确的拐点的。但是我们能做的清晰的判断就是：有瓶颈！

所以对 TPS 曲线来说，它可以明确告诉我们的就是：

1. 有没有瓶颈：其实准确说所有的系统都有性能瓶颈，只看我们在哪个量级在做性能测试了。
2. 瓶颈和压力有没有关系：TPS 随着压力的变化而变化，那就是有关系。不管压力增不增加，TPS 都会出现曲线趋势问题，那就是无关。

> 这时你可能会问，为什么不看响应时间就武断地下此结论呢？其实响应时间是用来判断业务有多快的，而 TPS 才是用来判断容量有多大的。

- 响应时间的曲线

我们还是来看看响应时间，下面看一张响应时间图：

![5](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222802.png)

它对应的线程图是：

![6](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222818.png)

随着线程的增多，响应时间也在增加。再来看它们对应的 TPS 图：

![7](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222832.png)

到第 40 个线程时，TPS 基本上达到上限，为 2500 左右。响应时间随着线程数的增加而增加了，系统的瓶颈显而易见地出现了。

> 但是，如果只让你看 TPS 曲线，你是不是也会有同样的判断？那就是：有瓶颈！并且和压力有关？所以说，其实 TPS 就可以告诉我们系统有没有瓶颈了，而响应时间是用来判断业务有多快的。

## 2. 线程递增的策略

讲完响应时间之后，我们再来看下线程递增。首先，我们来看两个场景的执行对比。

场景 1 的线程图：

![8](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222853.png)

场景 1 的 TPS 图：

![9](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222909.png)

场景 1 的响应时间图：

![10](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222924.png)

场景 2 的线程图：

![11](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222939.png)

场景 2 的 TPS 图：

![12](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115222956.png)

场景 2 的响应时间图：

![13](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223010.png)

这两个场景的比对如下：

![15](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223106.jpeg)

在两个场景中，TPS 的上限都达到了 400TPS。但是在场景 2 中，只要 40 个线程即可达到，但场景 1 中居然用到了 500 线程，显然压力过大，所以响应时间才那么长。

场景 2 使用了递增的策略，在每个阶梯递增的过程中，出现了抖动，这就明显是系统设置的不合理导致的。设置不合理，有两种可能性：1. 资源的动态分配不合理，像后端线程池、内存、缓存等等；2. 数据没有预热。

那么，对于场景中线程（有些工具中叫虚拟用户）递增的策略，我们要做到以下几点：
1. 场景中的线程递增一定是连续的，并且在递增的过程中也是有梯度的。
2. 场景中的线程递增一定要和 TPS 的递增有比例关系，而不是突然达到最上限。后面在场景的篇幅中我们会再说它们之间的比例关系。
3. 上面两点针对的是常规的性能场景。对于秒杀类的场景，我们前期一定是做好了系统预热的工作的，在预热之后，线程突增产生的压力，也是在可处理范围的。这时，我们可以设计线程突增的场景来看系统瞬间的处理能力。如果不能模拟出秒杀的陡增，就是不合理的场景。

这里给出我做性能场景递增的经验值：

![16](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223124.jpeg)

## 3. 性能衰减的过程

有了瓶颈的判断能力，也有了线程递增的意识，那么下面在场景执行中，我们就要有判断性能衰减的能力了。

下面是一张在压力过程中产生的结果图：

![17](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223140.png)

在递增的压力过程中，随着用户数的增加。我们可以做几次计算。

第一次计算，在线程达到 24 时，TPS 为 1810.6，也就是每线程每秒发出 75.44 个请求。

第二次计算，在线程达到 72 时，TPS 为 4375.1，也就是每线程每秒发出 60.77 个请求。

第三次计算，在线程达到 137 时，TPS 为 5034，也就是每线程每秒发出 36.74 个请求。

通过这三次计算，我们可以看到，每线程每秒发出的请求数在变少，但是整体 TPS 是在增加的。

但实际上，通过我们的计算可以知道，性能是在不断地衰减的。我们来看一张统计图：

![18](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223155.png)

通过红线的大致比对可以知道，当每线程每秒的请求数降到 55 左右的时候，TPS 就达到上限了，大概在 5000 左右，再接着往上增加线程已经没有用了，响应时间开始往上增加了。这就是性能衰减的过程。

只要每线程每秒的 TPS 开始变少，就意味着性能瓶颈已经出现了。但是瓶颈出现之后，并不是说服务器的处理能力（这里我们用 TPS 来描述）会下降，应该说 TPS 仍然会上升，在性能不断衰减的过程中，TPS 就会达到上限。

如果我们只是为了得到最大 TPS，那就可以停止场景了。但是，如果我们要扩大化性能瓶颈，也就是说为了让瓶颈更为明显，就完全不需要停止场景，只要不报错，就接着往上压，一直压到我们要说的下一个话题——响应时间变长，需要拆分。

## 4. 响应时间的拆分

在判断了瓶颈之后，我们需要找到问题出现在什么地方。在压力工具上看到的响应时间，都是经过了后端的每一个系统的。

我们看下这张图。

![19](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223212.jpeg)

一个应用，一个 DB，结果也拆分出了 8 个时间段。

如果我们是这样的架构，拆分时间应该是比较清楚的。

![21](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223241.jpeg)

首先我们需要查看 Nginx 上的时间。

```log
14.131.17.129 - - [09/Dec/2019:08:08:09 +0000] "GET / HTTP/1.1" 200 25317 0.028 0.028
```

> 最后两列中，前面是请求时间的 28ms，后面是后端响应时间的 28ms。同时，我们再到 Tomcat 上去看时间。

再到 Tomcat 上去看时间。

```log
172.18.0.1 - - [09/Dec/2019:08:08:09 +0000] "GET / HTTP/1.1" 200 25317 28 27 http-nio-8080-exec-1
```

> 请求时间消耗了 28ms，响应时间消耗了 27ms。

从这就可以看得出 Nginx 基本上没消耗时间，因为它和 Tomcat 上的请求响应时间非常接近。

接着再来看一下前端的时间消耗。

![22](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223256.png)

从这里可以看到，从发出请求到接收到第一个字节，即 TTFB 是 55.01ms，内容下载用了 11.75ms。

TTFB 中显然包括了后端一系列处理和网络传输的时间，如下图所示。

![23](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223318.jpeg)

如果接收完了就是这个状态。

![24](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223335.jpeg)

所以，我觉得用 TTFB 描述网络的健康状态并不合理。如果用 Content Download 来描述会更为合理。比如我们上面的这个例子中，那就是 11.75ms 下载了 25317 Bytes 的内容。

Tomcat 上基本上是消耗了处理的所有时间，当然这中间也包括了 MySQL 花费的时间。而前端看到的其他时间就消耗在了网络中。

当然，如果是下面这种情况的话，再一个个拆就比较辛苦了，需要换另一种方式。

![25](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223351.jpeg)

如果想知道每个系统消耗了多长时间，那么我们就需要链路监控工具来拆分时间了。比如像这样来拆分：

![26](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223407.png)

当我们拆分到了某个环节之后，就有了下一步的动作：构建分析决策树。

## 5. 构建分析决策树

分析决策树，对性能测试分析人员实在是太重要了，是性能分析中不可或缺的一环。它是对架构的梳理，是对系统的梳理，是对问题的梳理，是对查找证据链过程的梳理，是对分析思路的梳理。它起的是纵观全局，高屋建瓴的指导作用。

通过上面的几个步骤，我们就会知道时间消耗在了哪个节点上。那么之后呢？又当如何？总要找到根本的原因才可以吧，我画了如下的分析决策图：

![27](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223433.jpeg)

从压力工具中，只需要知道 TPS、响应时间和错误率三条曲线，就可以明确判断瓶颈是否存在。再通过分段分层策略，结合监控平台、日志平台，或者其他的实时分析平台，知道架构中的哪个环节有问题，然后再根据更细化的架构图一一拆解下去。

我们再来看一下操作系统分析决策树，我在这里需要强调一下，操作系统的分析决策树，不可以绕过。

![29](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223507.png)

看到下面这样的图，你是不是有种手足无措的感觉？

![30](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223524.png)

中断能占 40%，sy CPU 也能占 40%。这系统还用干业务的事吗？全干自己的事去了，可见操作系统有问题！

而实际情况是，这个主机上只有一个网卡队列，而请求量又比较大。

![31](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223536.png)

所以要解决的是网卡队列的问题，至于怎么解决，那手段就多了。可以换个服务器，可以多加几个队列，可以多接几个节点…

以上只是给出几个性能分析过程中常见的决策树示例。在后续的分析过程实例中，我们将秉承着这种分析思路，一步步地走到瓶颈的面前。

## 6. 场景的比对

当你觉得系统中哪个环节不行的时候， 又没能力分析它，你可以直接做该环节的增加。

举例来说，我们现在有一个如下的架构：

![32](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223557.png)

可以得到这样的结果：

![33](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223610.png)

从 TPS 曲线中，我们可以明显看到系统是有瓶颈的，但是并不知道在哪里。鉴于系统架构如此简单，我们索性直接在某环节上加上一台服务器，变成这样：

![34](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223626.png)

然后得到如下数据：

![35](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223642.png)

发现结果没有明显的变化。再接着加其他节点，我加了更多的 JMeter 机器。

![36](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223709.png)

再来看下结果：

![37](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20211115223729.png)

TPS 增加了！这就是我说的场景比对。

当我们不知道系统中哪个环节存在性能瓶颈时，对架构并不复杂的系统来说，可以使用这样的手段，来做替换法，以快速定位问题。

